{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b03c477",
   "metadata": {},
   "source": [
    "# Browns Performance Science â€” Tracking Analysis\n",
    "\n",
    "**Single anonymized practice session (10 Hz tracking data)**\n",
    "\n",
    "This notebook is the complete, self-contained analysis pipeline. It loads raw CSV data, performs quality control, computes all workload metrics, detects session phases, and generates three coach-ready visualizations.\n",
    "\n",
    "**Units (hard requirement):**\n",
    "- Distance: yards\n",
    "- Speed: miles per hour (mph)\n",
    "- Acceleration/Deceleration: m/sÂ²\n",
    "\n",
    "**Conversion factors:**\n",
    "- yd/s â†’ mph: Ã— 3600/1760 â‰ˆ 2.04545\n",
    "- yd/sÂ² â†’ m/sÂ²: Ã— 0.9144\n",
    "\n",
    "**Distance policy:** Speed-derived step distance (`s Ã— dt`) is the primary distance metric. XY displacement corroborates (r = 0.979). Vendor `dis` column is unreliable and used only for QA cross-check.\n",
    "\n",
    "**Continuity policy:** Rolling windows, events, and trajectory lines reset at flagged gaps (>1s) and improbable jumps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceabe57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Data path: C:\\docker_projects\\browns_performance_science_fellowship\\data\\tracking_data.csv\n",
      "ðŸ“ Output dir: C:\\docker_projects\\browns_performance_science_fellowship\\outputs\n",
      "âœ“ Paths configured\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Browns Performance Science Fellow â€” Tracking Analysis Pipeline\n",
    "==============================================================\n",
    "Single-player anonymized practice session (10 Hz tracking data).\n",
    "\n",
    "Units (hard requirement):\n",
    "  - Distance: yards\n",
    "  - Speed: miles per hour (mph)\n",
    "  - Acceleration/Deceleration: m/sÂ²\n",
    "\n",
    "Conversion factors:\n",
    "  - yd/s â†’ mph:  multiply by 3600/1760 â‰ˆ 2.045454545\n",
    "  - yd/sÂ² â†’ m/sÂ²: multiply by 0.9144\n",
    "\n",
    "Author: Geoff\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# â”€â”€ Paths â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Use relative paths (works on Windows, Linux, and in Docker)\n",
    "# Assuming notebook is in notebooks/ directory\n",
    "NOTEBOOK_DIR = Path(\".\").resolve()\n",
    "if NOTEBOOK_DIR.name == \"notebooks\":\n",
    "    BASE_DIR = NOTEBOOK_DIR.parent\n",
    "else:\n",
    "    BASE_DIR = NOTEBOOK_DIR\n",
    "\n",
    "DATA_PATH = BASE_DIR / \"data\" / \"tracking_data.csv\"\n",
    "OUT_DIR = BASE_DIR / \"outputs\"\n",
    "FIG_DIR = OUT_DIR / \"figures\"\n",
    "TABLE_DIR = OUT_DIR / \"tables\"\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "for d in [FIG_DIR, TABLE_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"ðŸ“ Data path: {DATA_PATH}\")\n",
    "print(f\"ðŸ“ Output dir: {OUT_DIR}\")\n",
    "print(f\"âœ“ Paths configured\\n\")\n",
    "\n",
    "# â”€â”€ Constants â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "YDS_TO_MPH = 3600.0 / 1760.0        # 2.045454545...\n",
    "YDS2_TO_MS2 = 0.9144\n",
    "EXPECTED_CADENCE_S = 0.1\n",
    "GAP_THRESHOLD_S = 1.0                # flag gaps > 1 second\n",
    "TELEPORT_SPEED_YDS = 25.0            # yd/s (~51 mph) â€“ impossible for humans\n",
    "\n",
    "# Speed band definitions (mph) â€” justified by NFL tracking conventions\n",
    "SPEED_BANDS = [\n",
    "    {\"name\": \"Standing\",    \"lower\": 0.0,  \"upper\": 1.0},\n",
    "    {\"name\": \"Walking\",     \"lower\": 1.0,  \"upper\": 4.0},\n",
    "    {\"name\": \"Jogging\",     \"lower\": 4.0,  \"upper\": 8.0},\n",
    "    {\"name\": \"Running\",     \"lower\": 8.0,  \"upper\": 13.0},\n",
    "    {\"name\": \"High-Speed\",  \"lower\": 13.0, \"upper\": 16.0},\n",
    "    {\"name\": \"Sprint\",      \"lower\": 16.0, \"upper\": None},\n",
    "]\n",
    "\n",
    "HSR_THRESHOLD_MPH = 13.0\n",
    "SPRINT_THRESHOLD_MPH = 16.0\n",
    "ACCEL_THRESHOLD_MS2 = 2.0     # â‰¥2.0 m/sÂ² = high accel event\n",
    "DECEL_THRESHOLD_MS2 = -2.0   # â‰¤-2.0 m/sÂ² = high decel event\n",
    "\n",
    "# Rolling window durations for peak demand analysis\n",
    "PEAK_WINDOWS_S = [15, 30, 60, 120, 300]\n",
    "\n",
    "# Phase detection parameters\n",
    "PHASE_BIN_S = 120            # 2-minute bins for phase detection\n",
    "PHASE_MERGE_GAP_MIN = 2.0   # merge rest blocks shorter than 2 min into adjacent active\n",
    "MIN_ACTIVE_SPEED_MPH = 1.5  # speed threshold for \"active\" classification\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# UTILITY FUNCTION: Convert NumPy types to Python native types\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "def convert_numpy_to_python(obj):\n",
    "    \"\"\"\n",
    "    Recursively convert all NumPy types in nested data structures to Python native types.\n",
    "    \n",
    "    This function handles:\n",
    "    - NumPy integers (int8, int16, int32, int64) â†’ Python int\n",
    "    - NumPy floats (float16, float32, float64) â†’ Python float\n",
    "    - NumPy booleans (bool_) â†’ Python bool\n",
    "    - Nested dictionaries and lists (recursive)\n",
    "    - NaN and infinity values\n",
    "    \n",
    "    Args:\n",
    "        obj: Any Python object (dict, list, NumPy type, or native type)\n",
    "    \n",
    "    Returns:\n",
    "        The same structure with all NumPy types converted to Python native types\n",
    "    \"\"\"\n",
    "    # Handle None\n",
    "    if obj is None:\n",
    "        return None\n",
    "    \n",
    "    # Handle NumPy scalar types\n",
    "    if isinstance(obj, np.generic):\n",
    "        # Convert NumPy integers to Python int\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        # Convert NumPy floats to Python float\n",
    "        elif isinstance(obj, np.floating):\n",
    "            # Handle NaN and infinity\n",
    "            if np.isnan(obj):\n",
    "                return None  # or return float('nan')\n",
    "            elif np.isinf(obj):\n",
    "                return None  # or return float('inf') / float('-inf')\n",
    "            return float(obj)\n",
    "        # Convert NumPy booleans to Python bool\n",
    "        elif isinstance(obj, np.bool_):\n",
    "            return bool(obj)\n",
    "        # Fallback: convert to Python type\n",
    "        return obj.item()\n",
    "    \n",
    "    # Handle dictionaries recursively\n",
    "    elif isinstance(obj, dict):\n",
    "        return {key: convert_numpy_to_python(value) for key, value in obj.items()}\n",
    "    \n",
    "    # Handle lists and tuples recursively\n",
    "    elif isinstance(obj, (list, tuple)):\n",
    "        return type(obj)(convert_numpy_to_python(item) for item in obj)\n",
    "    \n",
    "    # Handle pandas Timestamp (convert to string)\n",
    "    elif hasattr(obj, 'isoformat'):  # datetime-like objects\n",
    "        return str(obj)\n",
    "    \n",
    "    # Return as-is for Python native types (int, float, str, bool)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798b9535",
   "metadata": {},
   "source": [
    "## STEP 1: LOAD AND QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ec9a9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: Load raw data and quality control\n"
     ]
    }
   ],
   "source": [
    "print(\"STEP 1: Load raw data and quality control\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a72a480",
   "metadata": {},
   "source": [
    "## STEP 1: LOAD AND QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64edcb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rows: 65,410\n",
      "  Time span: 2025-10-09 18:20:00.200000+00:00 â†’ 2025-10-09 20:12:13.100000+00:00\n",
      "  Duration: 6732.9s (112.2 min)\n",
      "  Cadence: 100.0% of samples at expected 0.1s\n",
      "  Gaps > 1.0s: 6 (max: 80.3s)\n",
      "  Teleport samples (>25.0 yd/s): 2\n",
      "  Speed vs XY-derived speed correlation: 0.979\n",
      "  Distance from speed*dt: 4840.8 yd\n",
      "  Distance from XY displacement: 4909.6 yd\n",
      "  Distance from 'dis' column: 1226.5 yd (vendor â€” unreliable, not used)\n",
      "\n",
      "  QC Status: PASS\n"
     ]
    }
   ],
   "source": [
    "raw = pd.read_csv(DATA_PATH)\n",
    "raw[\"ts\"] = pd.to_datetime(raw[\"ts\"], utc=True)\n",
    "raw = raw.sort_values(\"ts\").reset_index(drop=True)\n",
    "\n",
    "# Compute dt (time delta between consecutive samples)\n",
    "raw[\"dt\"] = raw[\"ts\"].diff().dt.total_seconds()\n",
    "raw.loc[0, \"dt\"] = EXPECTED_CADENCE_S  # first row has no predecessor\n",
    "\n",
    "# â”€â”€ QC: Timestamp gaps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "gap_mask = raw[\"dt\"] > GAP_THRESHOLD_S\n",
    "gap_count = gap_mask.sum()\n",
    "max_gap_s = raw[\"dt\"].max()\n",
    "pct_on_cadence = ((raw[\"dt\"] - EXPECTED_CADENCE_S).abs() < 0.02).mean() * 100\n",
    "\n",
    "print(f\"  Rows: {len(raw):,}\")\n",
    "print(f\"  Time span: {raw['ts'].iloc[0]} â†’ {raw['ts'].iloc[-1]}\")\n",
    "print(f\"  Duration: {(raw['ts'].iloc[-1] - raw['ts'].iloc[0]).total_seconds():.1f}s \"\n",
    "      f\"({(raw['ts'].iloc[-1] - raw['ts'].iloc[0]).total_seconds()/60:.1f} min)\")\n",
    "print(f\"  Cadence: {pct_on_cadence:.1f}% of samples at expected 0.1s\")\n",
    "print(f\"  Gaps > {GAP_THRESHOLD_S}s: {gap_count} (max: {max_gap_s:.1f}s)\")\n",
    "\n",
    "# â”€â”€ QC: Flag gaps and teleports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "raw[\"is_gap\"] = gap_mask\n",
    "\n",
    "# XY displacement check\n",
    "raw[\"xy_step\"] = np.sqrt(raw[\"x\"].diff()**2 + raw[\"y\"].diff()**2)\n",
    "raw[\"xy_speed_yds\"] = raw[\"xy_step\"] / raw[\"dt\"].replace(0, np.nan)\n",
    "teleport_mask = raw[\"xy_speed_yds\"] > TELEPORT_SPEED_YDS\n",
    "raw[\"is_teleport\"] = teleport_mask\n",
    "print(f\"  Teleport samples (>{TELEPORT_SPEED_YDS} yd/s): {teleport_mask.sum()}\")\n",
    "\n",
    "# â”€â”€ QC: Speed-vs-XY consistency â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "normal = ~raw[\"is_gap\"] & ~raw[\"is_teleport\"] & (raw[\"dt\"] > 0)\n",
    "if normal.sum() > 100:\n",
    "    speed_xy_corr = np.corrcoef(\n",
    "        raw.loc[normal, \"s\"],\n",
    "        raw.loc[normal, \"xy_speed_yds\"].fillna(0)\n",
    "    )[0, 1]\n",
    "    print(f\"  Speed vs XY-derived speed correlation: {speed_xy_corr:.3f}\")\n",
    "\n",
    "# â”€â”€ QC: dis column validation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "dist_speed = (raw[\"s\"] * raw[\"dt\"]).sum()\n",
    "dist_xy = raw[\"xy_step\"].sum()\n",
    "dist_dis = raw[\"dis\"].sum()\n",
    "print(f\"  Distance from speed*dt: {dist_speed:.1f} yd\")\n",
    "print(f\"  Distance from XY displacement: {dist_xy:.1f} yd\")\n",
    "print(f\"  Distance from 'dis' column: {dist_dis:.1f} yd (vendor â€” unreliable, not used)\")\n",
    "\n",
    "# Assign continuity block IDs (reset at gaps)\n",
    "raw[\"block_id\"] = raw[\"is_gap\"].cumsum()\n",
    "\n",
    "# â”€â”€ QC Summary table â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "qc_summary = {\n",
    "    \"total_rows\": len(raw),\n",
    "    \"session_start_utc\": str(raw[\"ts\"].iloc[0]),\n",
    "    \"session_end_utc\": str(raw[\"ts\"].iloc[-1]),\n",
    "    \"duration_s\": round((raw[\"ts\"].iloc[-1] - raw[\"ts\"].iloc[0]).total_seconds(), 1),\n",
    "    \"pct_at_expected_cadence\": round(pct_on_cadence, 2),\n",
    "    \"gap_count\": int(gap_count),\n",
    "    \"max_gap_s\": round(max_gap_s, 2),\n",
    "    \"teleport_count\": int(teleport_mask.sum()),\n",
    "    \"continuity_blocks\": int(raw[\"block_id\"].nunique()),\n",
    "    \"distance_speed_yd\": round(dist_speed, 1),\n",
    "    \"distance_xy_yd\": round(dist_xy, 1),\n",
    "    \"distance_dis_yd\": round(dist_dis, 1),\n",
    "    \"speed_xy_correlation\": round(speed_xy_corr, 3) if normal.sum() > 100 else None,\n",
    "    \"qc_status\": \"PASS\" if gap_count <= 10 and pct_on_cadence > 95 else \"WARN\",\n",
    "}\n",
    "print(f\"\\n  QC Status: {qc_summary['qc_status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917d4703",
   "metadata": {},
   "source": [
    "## STEP 2: UNIT CONVERSIONS AND DERIVED COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cee03e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 2: Unit conversions and derived columns\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 2: Unit conversions and derived columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6868dc27",
   "metadata": {},
   "source": [
    "## STEP 2: UNIT CONVERSIONS AND DERIVED COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40931913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Conversion: yd/s â†’ mph (factor: 2.045455)\n",
      "  Conversion: yd/sÂ² â†’ m/sÂ² (factor: 0.9144)\n",
      "  Speed bands: Standing, Walking, Jogging, Running, High-Speed, Sprint\n",
      "  HSR threshold: 13.0 mph | Sprint: 16.0 mph\n",
      "  Accel threshold: 2.0 m/sÂ² | Decel: -2.0 m/sÂ²\n"
     ]
    }
   ],
   "source": [
    "df = raw.copy()\n",
    "\n",
    "# Speed: yd/s â†’ mph\n",
    "df[\"speed_mph\"] = df[\"s\"] * YDS_TO_MPH\n",
    "\n",
    "# Acceleration: yd/sÂ² â†’ m/sÂ² (using signed sa for accel/decel direction)\n",
    "df[\"accel_ms2\"] = df[\"sa\"] * YDS2_TO_MS2\n",
    "df[\"accel_mag_ms2\"] = df[\"a\"] * YDS2_TO_MS2\n",
    "\n",
    "# Step distance (speed-derived, yards)\n",
    "df[\"step_dist_yd\"] = df[\"s\"] * df[\"dt\"]\n",
    "# Zero out step distance at gaps (don't accumulate distance across discontinuities)\n",
    "df.loc[df[\"is_gap\"], \"step_dist_yd\"] = 0.0\n",
    "\n",
    "# Elapsed time (seconds and minutes from session start)\n",
    "df[\"elapsed_s\"] = (df[\"ts\"] - df[\"ts\"].iloc[0]).dt.total_seconds()\n",
    "df[\"elapsed_min\"] = df[\"elapsed_s\"] / 60.0\n",
    "\n",
    "# Speed band classification\n",
    "def classify_speed_band(speed_mph):\n",
    "    for band in SPEED_BANDS:\n",
    "        upper = band[\"upper\"] if band[\"upper\"] is not None else np.inf\n",
    "        if band[\"lower\"] <= speed_mph < upper:\n",
    "            return band[\"name\"]\n",
    "    return SPEED_BANDS[-1][\"name\"]\n",
    "\n",
    "df[\"speed_band\"] = df[\"speed_mph\"].apply(classify_speed_band)\n",
    "\n",
    "# HSR / Sprint flags\n",
    "df[\"is_hsr\"] = df[\"speed_mph\"] >= HSR_THRESHOLD_MPH\n",
    "df[\"is_sprint\"] = df[\"speed_mph\"] >= SPRINT_THRESHOLD_MPH\n",
    "df[\"is_accel\"] = df[\"accel_ms2\"] >= ACCEL_THRESHOLD_MS2\n",
    "df[\"is_decel\"] = df[\"accel_ms2\"] <= DECEL_THRESHOLD_MS2\n",
    "\n",
    "print(f\"  Conversion: yd/s â†’ mph (factor: {YDS_TO_MPH:.6f})\")\n",
    "print(f\"  Conversion: yd/sÂ² â†’ m/sÂ² (factor: {YDS2_TO_MS2})\")\n",
    "print(f\"  Speed bands: {', '.join(b['name'] for b in SPEED_BANDS)}\")\n",
    "print(f\"  HSR threshold: {HSR_THRESHOLD_MPH} mph | Sprint: {SPRINT_THRESHOLD_MPH} mph\")\n",
    "print(f\"  Accel threshold: {ACCEL_THRESHOLD_MS2} m/sÂ² | Decel: {DECEL_THRESHOLD_MS2} m/sÂ²\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455e15a5",
   "metadata": {},
   "source": [
    "## STEP 3: SESSION-LEVEL METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f07ce9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 3: Session-level workload metrics\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 3: Session-level workload metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1c6ddb",
   "metadata": {},
   "source": [
    "## STEP 3: SESSION-LEVEL METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "481fa973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Total distance: 4839.7 yd\n",
      "\n",
      "  Speed Band Distance Breakdown:\n",
      "    Standing    :   564.7 yd ( 11.7%)  |  64.3 min ( 57.3%)\n",
      "    Walking     :  2520.2 yd ( 52.1%)  |  39.8 min ( 35.5%)\n",
      "    Jogging     :   952.3 yd ( 19.7%)  |   5.7 min (  5.0%)\n",
      "    Running     :   585.9 yd ( 12.1%)  |   2.0 min (  1.7%)\n",
      "    High-Speed  :   132.2 yd (  2.7%)  |   0.3 min (  0.3%)\n",
      "    Sprint      :    84.4 yd (  1.7%)  |   0.2 min (  0.1%)\n",
      "\n",
      "  Mean speed: 1.51 mph\n",
      "  Median speed: 0.71 mph\n",
      "  P95 speed: 5.57 mph\n",
      "  Max speed: 18.71 mph\n",
      "  Peak accel: 4.93 m/sÂ²\n",
      "  Peak decel: -5.12 m/sÂ²\n",
      "  HSR distance: 216.7 yd (29.2s)\n",
      "  Sprint distance: 84.4 yd (10.0s)\n",
      "\n",
      "  HSR events (â‰¥1s): 6\n",
      "  Sprint events (â‰¥1s): 4\n",
      "  Accel events (â‰¥2.0 m/sÂ², â‰¥1s): 11\n",
      "  Decel events (â‰¤-2.0 m/sÂ², â‰¥1s): 2\n"
     ]
    }
   ],
   "source": [
    "# â”€â”€ 3a: Total distance â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "total_distance_yd = df[\"step_dist_yd\"].sum()\n",
    "print(f\"  Total distance: {total_distance_yd:.1f} yd\")\n",
    "\n",
    "# â”€â”€ 3b: Distance by speed band â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "speed_band_dist = df.groupby(\"speed_band\").agg(\n",
    "    distance_yd=(\"step_dist_yd\", \"sum\"),\n",
    "    sample_count=(\"step_dist_yd\", \"count\"),\n",
    "    time_s=(\"dt\", \"sum\"),\n",
    ").reindex([b[\"name\"] for b in SPEED_BANDS]).fillna(0)\n",
    "\n",
    "speed_band_dist[\"distance_pct\"] = (speed_band_dist[\"distance_yd\"] / total_distance_yd * 100).round(1)\n",
    "speed_band_dist[\"time_min\"] = (speed_band_dist[\"time_s\"] / 60).round(1)\n",
    "speed_band_dist[\"time_pct\"] = (speed_band_dist[\"time_s\"] / df[\"dt\"].sum() * 100).round(1)\n",
    "\n",
    "print(\"\\n  Speed Band Distance Breakdown:\")\n",
    "for band_name, row in speed_band_dist.iterrows():\n",
    "    print(f\"    {band_name:12s}: {row['distance_yd']:7.1f} yd ({row['distance_pct']:5.1f}%)  \"\n",
    "          f\"| {row['time_min']:5.1f} min ({row['time_pct']:5.1f}%)\")\n",
    "\n",
    "# â”€â”€ 3c: Speed and acceleration statistics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "metrics = {\n",
    "    \"total_distance_yd\": round(total_distance_yd, 1),\n",
    "    \"mean_speed_mph\": round(df[\"speed_mph\"].mean(), 2),\n",
    "    \"median_speed_mph\": round(df[\"speed_mph\"].median(), 2),\n",
    "    \"p95_speed_mph\": round(df[\"speed_mph\"].quantile(0.95), 2),\n",
    "    \"max_speed_mph\": round(df[\"speed_mph\"].max(), 2),\n",
    "    \"mean_accel_ms2\": round(df[\"accel_ms2\"].mean(), 3),\n",
    "    \"peak_accel_ms2\": round(df[\"accel_ms2\"].max(), 2),\n",
    "    \"peak_decel_ms2\": round(df[\"accel_ms2\"].min(), 2),\n",
    "    \"p95_accel_ms2\": round(df[\"accel_ms2\"].quantile(0.99), 2),\n",
    "    \"p05_decel_ms2\": round(df[\"accel_ms2\"].quantile(0.01), 2),\n",
    "    \"hsr_distance_yd\": round(df.loc[df[\"is_hsr\"], \"step_dist_yd\"].sum(), 1),\n",
    "    \"sprint_distance_yd\": round(df.loc[df[\"is_sprint\"], \"step_dist_yd\"].sum(), 1),\n",
    "    \"hsr_time_s\": round(df.loc[df[\"is_hsr\"], \"dt\"].sum(), 1),\n",
    "    \"sprint_time_s\": round(df.loc[df[\"is_sprint\"], \"dt\"].sum(), 1),\n",
    "}\n",
    "\n",
    "print(f\"\\n  Mean speed: {metrics['mean_speed_mph']} mph\")\n",
    "print(f\"  Median speed: {metrics['median_speed_mph']} mph\")\n",
    "print(f\"  P95 speed: {metrics['p95_speed_mph']} mph\")\n",
    "print(f\"  Max speed: {metrics['max_speed_mph']} mph\")\n",
    "print(f\"  Peak accel: {metrics['peak_accel_ms2']} m/sÂ²\")\n",
    "print(f\"  Peak decel: {metrics['peak_decel_ms2']} m/sÂ²\")\n",
    "print(f\"  HSR distance: {metrics['hsr_distance_yd']} yd ({metrics['hsr_time_s']}s)\")\n",
    "print(f\"  Sprint distance: {metrics['sprint_distance_yd']} yd ({metrics['sprint_time_s']}s)\")\n",
    "\n",
    "# â”€â”€ 3d: Event detection (contiguous threshold exposure >= 1s) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def count_events(mask, dt_series, min_duration_s=1.0):\n",
    "    \"\"\"Count contiguous True runs lasting >= min_duration_s.\"\"\"\n",
    "    events = []\n",
    "    in_event = False\n",
    "    event_start = 0\n",
    "    event_duration = 0.0\n",
    "    event_distance = 0.0\n",
    "    for i in range(len(mask)):\n",
    "        if mask.iloc[i]:\n",
    "            if not in_event:\n",
    "                in_event = True\n",
    "                event_start = i\n",
    "                event_duration = 0.0\n",
    "                event_distance = 0.0\n",
    "            event_duration += dt_series.iloc[i]\n",
    "            event_distance += df[\"step_dist_yd\"].iloc[i]\n",
    "        else:\n",
    "            if in_event:\n",
    "                if event_duration >= min_duration_s:\n",
    "                    events.append({\n",
    "                        \"start_idx\": event_start,\n",
    "                        \"end_idx\": i - 1,\n",
    "                        \"duration_s\": round(event_duration, 2),\n",
    "                        \"distance_yd\": round(event_distance, 1),\n",
    "                    })\n",
    "                in_event = False\n",
    "    # Handle event running to end\n",
    "    if in_event and event_duration >= min_duration_s:\n",
    "        events.append({\n",
    "            \"start_idx\": event_start,\n",
    "            \"end_idx\": len(mask) - 1,\n",
    "            \"duration_s\": round(event_duration, 2),\n",
    "            \"distance_yd\": round(event_distance, 1),\n",
    "        })\n",
    "    return events\n",
    "\n",
    "hsr_events = count_events(df[\"is_hsr\"], df[\"dt\"])\n",
    "sprint_events = count_events(df[\"is_sprint\"], df[\"dt\"])\n",
    "accel_events = count_events(df[\"is_accel\"], df[\"dt\"])\n",
    "decel_events = count_events(df[\"is_decel\"], df[\"dt\"])\n",
    "\n",
    "event_counts = {\n",
    "    \"hsr_event_count\": len(hsr_events),\n",
    "    \"sprint_event_count\": len(sprint_events),\n",
    "    \"accel_event_count\": len(accel_events),\n",
    "    \"decel_event_count\": len(decel_events),\n",
    "    \"hsr_total_distance_yd\": round(sum(e[\"distance_yd\"] for e in hsr_events), 1),\n",
    "    \"sprint_total_distance_yd\": round(sum(e[\"distance_yd\"] for e in sprint_events), 1),\n",
    "}\n",
    "print(f\"\\n  HSR events (â‰¥1s): {event_counts['hsr_event_count']}\")\n",
    "print(f\"  Sprint events (â‰¥1s): {event_counts['sprint_event_count']}\")\n",
    "print(f\"  Accel events (â‰¥{ACCEL_THRESHOLD_MS2} m/sÂ², â‰¥1s): {event_counts['accel_event_count']}\")\n",
    "print(f\"  Decel events (â‰¤{DECEL_THRESHOLD_MS2} m/sÂ², â‰¥1s): {event_counts['decel_event_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b5bcb1",
   "metadata": {},
   "source": [
    "## STEP 4: PEAK DEMAND â€” ROLLING WINDOWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cb7da69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 4: Peak demand rolling windows\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 4: Peak demand rolling windows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e162d4",
   "metadata": {},
   "source": [
    "## STEP 4: PEAK DEMAND â€” ROLLING WINDOWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e86d635e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best 15s :    74.4 yd ( 297.5 yd/min) @ min 109â€“109\n",
      "  Best 30s :    98.8 yd ( 197.7 yd/min) @ min 59â€“59\n",
      "  Best 1min:   135.1 yd ( 135.1 yd/min) @ min 58â€“59\n",
      "  Best 2min:   221.1 yd ( 110.5 yd/min) @ min 57â€“59\n",
      "  Best 5min:   432.4 yd (  86.5 yd/min) @ min 56â€“61\n"
     ]
    }
   ],
   "source": [
    "# For each window duration, find the top-1 window by distance (intensity = yd/min)\n",
    "# Windows must not span a gap boundary.\n",
    "peak_windows = []\n",
    "\n",
    "for window_s in PEAK_WINDOWS_S:\n",
    "    window_samples = int(window_s / EXPECTED_CADENCE_S)\n",
    "    best_dist = 0\n",
    "    best_start = 0\n",
    "\n",
    "    # Rolling sum of step distance\n",
    "    roll_dist = df[\"step_dist_yd\"].rolling(window_samples, min_periods=window_samples).sum()\n",
    "    # Rolling count of gaps within window (invalidate windows that span gaps)\n",
    "    roll_gaps = df[\"is_gap\"].astype(int).rolling(window_samples, min_periods=window_samples).sum()\n",
    "\n",
    "    valid = (roll_gaps == 0) & roll_dist.notna()\n",
    "    if valid.any():\n",
    "        best_idx = roll_dist[valid].idxmax()\n",
    "        best_dist = roll_dist[best_idx]\n",
    "        window_start_idx = best_idx - window_samples + 1\n",
    "\n",
    "        peak_windows.append({\n",
    "            \"window_s\": window_s,\n",
    "            \"window_label\": f\"{window_s // 60}min\" if window_s >= 60 else f\"{window_s}s\",\n",
    "            \"distance_yd\": round(best_dist, 1),\n",
    "            \"intensity_yd_min\": round(best_dist / (window_s / 60), 1),\n",
    "            \"start_idx\": int(window_start_idx),\n",
    "            \"end_idx\": int(best_idx),\n",
    "            \"start_utc\": str(df.loc[window_start_idx, \"ts\"]),\n",
    "            \"end_utc\": str(df.loc[best_idx, \"ts\"]),\n",
    "            \"start_elapsed_min\": round(df.loc[window_start_idx, \"elapsed_min\"], 1),\n",
    "            \"end_elapsed_min\": round(df.loc[best_idx, \"elapsed_min\"], 1),\n",
    "            \"mean_speed_mph\": round(df.loc[window_start_idx:best_idx, \"speed_mph\"].mean(), 2),\n",
    "            \"max_speed_mph\": round(df.loc[window_start_idx:best_idx, \"speed_mph\"].max(), 2),\n",
    "        })\n",
    "\n",
    "        label = f\"{window_s // 60}min\" if window_s >= 60 else f\"{window_s}s\"\n",
    "        print(f\"  Best {label:4s}: {best_dist:7.1f} yd ({best_dist / (window_s / 60):6.1f} yd/min) \"\n",
    "              f\"@ min {df.loc[window_start_idx, 'elapsed_min']:.0f}â€“{df.loc[best_idx, 'elapsed_min']:.0f}\")\n",
    "\n",
    "peak_windows_df = pd.DataFrame(peak_windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c46c4f",
   "metadata": {},
   "source": [
    "## STEP 5: SESSION PHASE SEGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b3aec20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 5: Session phase segmentation\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 5: Session phase segmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f66b77",
   "metadata": {},
   "source": [
    "## STEP 5: SESSION PHASE SEGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c99f9e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Detected 21 session phases:\n",
      "    Phase  1 [Rest         ]: min   0.0â€“  4.0 ( 4.0 min,   66.0 yd, max 4.1 mph)\n",
      "    Phase  2 [Low          ]: min   4.0â€“  6.0 ( 2.0 min,  113.2 yd, max 3.0 mph)\n",
      "    Phase  3 [Rest         ]: min   6.0â€“ 12.0 ( 6.0 min,  181.8 yd, max 4.2 mph)\n",
      "    Phase  4 [Moderate     ]: min  12.0â€“ 16.0 ( 4.0 min,  314.5 yd, max 8.8 mph)\n",
      "    Phase  5 [Rest         ]: min  16.0â€“ 20.0 ( 4.0 min,  147.1 yd, max 9.1 mph)\n",
      "    Phase  6 [Moderate-High]: min  20.0â€“ 22.0 ( 2.0 min,  157.5 yd, max 13.6 mph)\n",
      "    Phase  7 [Rest         ]: min  22.0â€“ 24.0 ( 2.0 min,   68.8 yd, max 9.0 mph)\n",
      "    Phase  8 [Moderate-High]: min  24.0â€“ 32.0 ( 8.0 min,  428.0 yd, max 14.5 mph)\n",
      "    Phase  9 [Rest         ]: min  32.0â€“ 34.0 ( 2.0 min,   29.2 yd, max 1.9 mph)\n",
      "    Phase 10 [Moderate     ]: min  34.0â€“ 38.0 ( 4.0 min,  217.1 yd, max 12.3 mph)\n",
      "    Phase 11 [Rest         ]: min  38.0â€“ 44.0 ( 6.0 min,  180.0 yd, max 8.3 mph)\n",
      "    Phase 12 [High         ]: min  44.0â€“ 48.0 ( 4.0 min,  296.4 yd, max 17.1 mph)\n",
      "    Phase 13 [Rest         ]: min  48.0â€“ 56.0 ( 8.0 min,  131.3 yd, max 13.2 mph)\n",
      "    Phase 14 [High         ]: min  56.0â€“ 60.0 ( 4.0 min,  355.1 yd, max 17.3 mph)\n",
      "    Phase 15 [Rest         ]: min  60.0â€“ 74.0 (14.0 min,  255.2 yd, max 11.0 mph)\n",
      "    Phase 16 [Moderate-High]: min  74.0â€“ 86.0 (12.0 min,  816.9 yd, max 15.0 mph)\n",
      "    Phase 17 [Rest         ]: min  86.0â€“ 90.0 ( 4.0 min,   52.3 yd, max 2.0 mph)\n",
      "    Phase 18 [Moderate-High]: min  90.0â€“ 96.0 ( 6.0 min,  443.5 yd, max 13.5 mph)\n",
      "    Phase 19 [Rest         ]: min  96.0â€“106.0 (10.0 min,  227.5 yd, max 11.8 mph)\n",
      "    Phase 20 [High         ]: min 106.0â€“110.0 ( 4.0 min,  332.1 yd, max 18.7 mph)\n",
      "    Phase 21 [Rest         ]: min 110.0â€“114.0 ( 2.2 min,   26.4 yd, max 4.5 mph)\n"
     ]
    }
   ],
   "source": [
    "# Resample into 2-minute bins for phase detection (reduces noise)\n",
    "bin_s = PHASE_BIN_S\n",
    "df[\"bin_phase\"] = (df[\"elapsed_s\"] // bin_s).astype(int)\n",
    "bin_stats = df.groupby(\"bin_phase\").agg(\n",
    "    mean_speed_mph=(\"speed_mph\", \"mean\"),\n",
    "    max_speed_mph=(\"speed_mph\", \"max\"),\n",
    "    distance_yd=(\"step_dist_yd\", \"sum\"),\n",
    "    elapsed_min=(\"elapsed_min\", \"first\"),\n",
    "    sample_count=(\"speed_mph\", \"count\"),\n",
    ").reset_index()\n",
    "\n",
    "# Classify each bin as active or rest\n",
    "bin_stats[\"is_active\"] = bin_stats[\"mean_speed_mph\"] > MIN_ACTIVE_SPEED_MPH\n",
    "\n",
    "# Merge adjacent bins of same type into phases\n",
    "phases = []\n",
    "current_type = None\n",
    "current_start_min = 0\n",
    "current_bins = []\n",
    "\n",
    "for _, brow in bin_stats.iterrows():\n",
    "    btype = \"Active\" if brow[\"is_active\"] else \"Rest\"\n",
    "    if btype != current_type:\n",
    "        if current_type is not None and current_bins:\n",
    "            phases.append({\n",
    "                \"type\": current_type,\n",
    "                \"start_min\": current_start_min,\n",
    "                \"end_min\": current_bins[-1][\"elapsed_min\"] + bin_s / 60.0,\n",
    "                \"bins\": current_bins,\n",
    "            })\n",
    "        current_type = btype\n",
    "        current_start_min = brow[\"elapsed_min\"]\n",
    "        current_bins = [brow.to_dict()]\n",
    "    else:\n",
    "        current_bins.append(brow.to_dict())\n",
    "\n",
    "if current_bins:\n",
    "    phases.append({\n",
    "        \"type\": current_type,\n",
    "        \"start_min\": current_start_min,\n",
    "        \"end_min\": current_bins[-1][\"elapsed_min\"] + bin_s / 60.0,\n",
    "        \"bins\": current_bins,\n",
    "    })\n",
    "\n",
    "# Merge short rest phases (< PHASE_MERGE_GAP_MIN) into adjacent active\n",
    "merged_phases = []\n",
    "for p in phases:\n",
    "    duration_min = p[\"end_min\"] - p[\"start_min\"]\n",
    "    if (p[\"type\"] == \"Rest\" and duration_min < PHASE_MERGE_GAP_MIN\n",
    "            and merged_phases and merged_phases[-1][\"type\"] == \"Active\"):\n",
    "        # Absorb into previous active phase\n",
    "        merged_phases[-1][\"end_min\"] = p[\"end_min\"]\n",
    "        merged_phases[-1][\"bins\"].extend(p[\"bins\"])\n",
    "    else:\n",
    "        merged_phases.append(p)\n",
    "\n",
    "# Second pass: merge adjacent Active phases that are now next to each other\n",
    "final_phases = []\n",
    "for p in merged_phases:\n",
    "    if final_phases and final_phases[-1][\"type\"] == p[\"type\"]:\n",
    "        final_phases[-1][\"end_min\"] = p[\"end_min\"]\n",
    "        final_phases[-1][\"bins\"].extend(p[\"bins\"])\n",
    "    else:\n",
    "        final_phases.append(p)\n",
    "merged_phases = final_phases\n",
    "\n",
    "# Build phase summary table\n",
    "phase_summary = []\n",
    "for i, p in enumerate(merged_phases):\n",
    "    phase_df = df[(df[\"elapsed_min\"] >= p[\"start_min\"]) & (df[\"elapsed_min\"] < p[\"end_min\"])]\n",
    "    if len(phase_df) == 0:\n",
    "        continue\n",
    "\n",
    "    dist = phase_df[\"step_dist_yd\"].sum()\n",
    "    dur_s = phase_df[\"dt\"].sum()\n",
    "    max_spd = phase_df[\"speed_mph\"].max()\n",
    "\n",
    "    # Intensity label\n",
    "    if p[\"type\"] == \"Rest\":\n",
    "        intensity = \"Rest\"\n",
    "    elif max_spd >= SPRINT_THRESHOLD_MPH:\n",
    "        intensity = \"High\"\n",
    "    elif max_spd >= HSR_THRESHOLD_MPH:\n",
    "        intensity = \"Moderate-High\"\n",
    "    elif max_spd >= 8.0:\n",
    "        intensity = \"Moderate\"\n",
    "    else:\n",
    "        intensity = \"Low\"\n",
    "\n",
    "    phase_summary.append({\n",
    "        \"phase\": i + 1,\n",
    "        \"type\": p[\"type\"],\n",
    "        \"intensity\": intensity,\n",
    "        \"start_min\": round(p[\"start_min\"], 1),\n",
    "        \"end_min\": round(p[\"end_min\"], 1),\n",
    "        \"duration_min\": round(dur_s / 60, 1),\n",
    "        \"distance_yd\": round(dist, 1),\n",
    "        \"distance_rate_yd_min\": round(dist / max(dur_s / 60, 0.01), 1),\n",
    "        \"max_speed_mph\": round(max_spd, 1),\n",
    "        \"hsr_distance_yd\": round(phase_df.loc[phase_df[\"is_hsr\"], \"step_dist_yd\"].sum(), 1),\n",
    "        \"sprint_distance_yd\": round(phase_df.loc[phase_df[\"is_sprint\"], \"step_dist_yd\"].sum(), 1),\n",
    "    })\n",
    "\n",
    "phase_df_summary = pd.DataFrame(phase_summary)\n",
    "\n",
    "print(f\"  Detected {len(phase_summary)} session phases:\")\n",
    "for _, p in phase_df_summary.iterrows():\n",
    "    print(f\"    Phase {int(p['phase']):2d} [{p['intensity']:13s}]: \"\n",
    "          f\"min {p['start_min']:5.1f}â€“{p['end_min']:5.1f} \"\n",
    "          f\"({p['duration_min']:4.1f} min, {p['distance_yd']:6.1f} yd, \"\n",
    "          f\"max {p['max_speed_mph']:.1f} mph)\")\n",
    "\n",
    "# Assign phase labels back to main df\n",
    "df[\"phase_id\"] = 0\n",
    "df[\"phase_intensity\"] = \"Unassigned\"\n",
    "for _, p in phase_df_summary.iterrows():\n",
    "    mask = (df[\"elapsed_min\"] >= p[\"start_min\"]) & (df[\"elapsed_min\"] < p[\"end_min\"])\n",
    "    df.loc[mask, \"phase_id\"] = int(p[\"phase\"])\n",
    "    df.loc[mask, \"phase_intensity\"] = p[\"intensity\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bc4654",
   "metadata": {},
   "source": [
    "## STEP 6: EARLY VS LATE COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bb23fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 6: Early vs late half comparison\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 6: Early vs late half comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42106fb",
   "metadata": {},
   "source": [
    "## STEP 6: EARLY VS LATE COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c217de14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Early half: 2335.0 yd (41.6 yd/min)\n",
      "  Late half:  2504.8 yd (44.6 yd/min)\n",
      "  Distance delta: +7.3%\n",
      "  HSR events: early=2, late=4\n",
      "  Sprint events: early=1, late=3\n"
     ]
    }
   ],
   "source": [
    "midpoint_s = df[\"elapsed_s\"].iloc[-1] / 2\n",
    "early = df[df[\"elapsed_s\"] <= midpoint_s]\n",
    "late = df[df[\"elapsed_s\"] > midpoint_s]\n",
    "\n",
    "early_late = []\n",
    "for label, subset in [(\"Early Half\", early), (\"Late Half\", late)]:\n",
    "    d = {\n",
    "        \"period\": label,\n",
    "        \"duration_min\": round(subset[\"dt\"].sum() / 60, 1),\n",
    "        \"distance_yd\": round(subset[\"step_dist_yd\"].sum(), 1),\n",
    "        \"distance_rate_yd_min\": round(\n",
    "            subset[\"step_dist_yd\"].sum() / max(subset[\"dt\"].sum() / 60, 0.01), 1\n",
    "        ),\n",
    "        \"mean_speed_mph\": round(subset[\"speed_mph\"].mean(), 2),\n",
    "        \"max_speed_mph\": round(subset[\"speed_mph\"].max(), 2),\n",
    "        \"hsr_distance_yd\": round(subset.loc[subset[\"is_hsr\"], \"step_dist_yd\"].sum(), 1),\n",
    "        \"sprint_distance_yd\": round(subset.loc[subset[\"is_sprint\"], \"step_dist_yd\"].sum(), 1),\n",
    "        \"hsr_events\": len(count_events(subset[\"is_hsr\"].reset_index(drop=True), subset[\"dt\"].reset_index(drop=True))),\n",
    "        \"sprint_events\": len(count_events(subset[\"is_sprint\"].reset_index(drop=True), subset[\"dt\"].reset_index(drop=True))),\n",
    "        \"accel_events\": len(count_events(subset[\"is_accel\"].reset_index(drop=True), subset[\"dt\"].reset_index(drop=True))),\n",
    "        \"decel_events\": len(count_events(subset[\"is_decel\"].reset_index(drop=True), subset[\"dt\"].reset_index(drop=True))),\n",
    "    }\n",
    "    early_late.append(d)\n",
    "\n",
    "early_late_df = pd.DataFrame(early_late)\n",
    "\n",
    "# Add delta row\n",
    "early_d = early_late_df.iloc[0]\n",
    "late_d = early_late_df.iloc[1]\n",
    "if early_d[\"distance_yd\"] > 0:\n",
    "    dist_delta_pct = round((late_d[\"distance_yd\"] - early_d[\"distance_yd\"]) / early_d[\"distance_yd\"] * 100, 1)\n",
    "else:\n",
    "    dist_delta_pct = 0\n",
    "\n",
    "print(f\"  Early half: {early_d['distance_yd']:.1f} yd ({early_d['distance_rate_yd_min']:.1f} yd/min)\")\n",
    "print(f\"  Late half:  {late_d['distance_yd']:.1f} yd ({late_d['distance_rate_yd_min']:.1f} yd/min)\")\n",
    "print(f\"  Distance delta: {dist_delta_pct:+.1f}%\")\n",
    "print(f\"  HSR events: early={early_d['hsr_events']}, late={late_d['hsr_events']}\")\n",
    "print(f\"  Sprint events: early={early_d['sprint_events']}, late={late_d['sprint_events']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eb14ec",
   "metadata": {},
   "source": [
    "## STEP 7: POSITION / ROLE INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bac3940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 7: Position / role inference\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 7: Position / role inference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd41e854",
   "metadata": {},
   "source": [
    "## STEP 7: POSITION / ROLE INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73cfb196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Field coverage: X=102 yd, Y=144 yd\n",
      "  HSR % of total distance: 4.5%\n",
      "  Sprint % of total distance: 1.7%\n",
      "  Mean direction change per sample: 7.6Â°\n",
      "  Max speed: 18.71 mph\n",
      "  Assessment: Skill position (likely WR/DB) â€” high max speed with\n",
      "              frequent direction changes and broad field coverage.\n"
     ]
    }
   ],
   "source": [
    "# Key indicators for position inference:\n",
    "# 1. Max speed (18.7 mph) â€” consistent with skill positions (WR, RB, DB, LB)\n",
    "# 2. Total distance for ~112 min session\n",
    "# 3. Movement pattern â€” do they move laterally or in straight lines?\n",
    "# 4. Field coverage area\n",
    "\n",
    "x_range = df[\"x\"].max() - df[\"x\"].min()\n",
    "y_range = df[\"y\"].max() - df[\"y\"].min()\n",
    "hsr_pct = metrics[\"hsr_distance_yd\"] / total_distance_yd * 100\n",
    "sprint_pct = metrics[\"sprint_distance_yd\"] / total_distance_yd * 100\n",
    "\n",
    "# Directional analysis â€” how often does player change direction?\n",
    "dir_changes = df[\"dir\"].diff().abs()\n",
    "# Normalize to [0, 180] (direction changes wrap around 360)\n",
    "dir_changes = dir_changes.where(dir_changes <= 180, 360 - dir_changes)\n",
    "mean_dir_change = dir_changes[normal].mean()\n",
    "\n",
    "print(f\"  Field coverage: X={x_range:.0f} yd, Y={y_range:.0f} yd\")\n",
    "print(f\"  HSR % of total distance: {hsr_pct:.1f}%\")\n",
    "print(f\"  Sprint % of total distance: {sprint_pct:.1f}%\")\n",
    "print(f\"  Mean direction change per sample: {mean_dir_change:.1f}Â°\")\n",
    "print(f\"  Max speed: {metrics['max_speed_mph']} mph\")\n",
    "print(f\"  Assessment: Skill position (likely WR/DB) â€” high max speed with\")\n",
    "print(f\"              frequent direction changes and broad field coverage.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810b2dfa",
   "metadata": {},
   "source": [
    "## STEP 8: FIGURE 1 â€” SPATIAL MOVEMENT MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a4ba9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 8: Generating Figure 1 â€” Spatial Movement Map\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 8: Generating Figure 1 â€” Spatial Movement Map\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0accfeba",
   "metadata": {},
   "source": [
    "## STEP 8: FIGURE 1 â€” SPATIAL MOVEMENT MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5642db36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: 01_space.png\n"
     ]
    }
   ],
   "source": [
    "fig1, axes1 = plt.subplots(1, 2, figsize=(16, 8), gridspec_kw={\"width_ratios\": [1.2, 1]})\n",
    "\n",
    "# â”€â”€ Left panel: Movement trace colored by speed band â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "ax = axes1[0]\n",
    "\n",
    "# Only plot continuous segments (skip gaps)\n",
    "band_colors = {\n",
    "    \"Standing\": \"#d4d4d4\",\n",
    "    \"Walking\": \"#93c5fd\",\n",
    "    \"Jogging\": \"#60a5fa\",\n",
    "    \"Running\": \"#f59e0b\",\n",
    "    \"High-Speed\": \"#ef4444\",\n",
    "    \"Sprint\": \"#dc2626\",\n",
    "}\n",
    "\n",
    "# Draw field outline (approximate)\n",
    "field_rect = plt.Rectangle(\n",
    "    (df[\"x\"].quantile(0.005), df[\"y\"].quantile(0.005)),\n",
    "    x_range * 0.99, y_range * 0.99,\n",
    "    linewidth=1.5, edgecolor=\"#9ca3af\", facecolor=\"#2d5016\", alpha=0.15, zorder=0\n",
    ")\n",
    "ax.add_patch(field_rect)\n",
    "\n",
    "# Plot movement by speed band (low speed first, high speed on top)\n",
    "for band_name in [\"Standing\", \"Walking\", \"Jogging\", \"Running\", \"High-Speed\", \"Sprint\"]:\n",
    "    band_mask = df[\"speed_band\"] == band_name\n",
    "    if band_mask.sum() > 0:\n",
    "        alpha = 0.15 if band_name in [\"Standing\", \"Walking\"] else 0.7\n",
    "        size = 0.3 if band_name in [\"Standing\", \"Walking\"] else 1.5\n",
    "        ax.scatter(\n",
    "            df.loc[band_mask, \"x\"], df.loc[band_mask, \"y\"],\n",
    "            c=band_colors[band_name], s=size, alpha=alpha,\n",
    "            label=band_name, zorder=1 if band_name in [\"Standing\", \"Walking\"] else 2,\n",
    "            rasterized=True,\n",
    "        )\n",
    "\n",
    "# Highlight peak windows on the map\n",
    "for pw in peak_windows:\n",
    "    if pw[\"window_s\"] <= 60:  # Only show shorter windows to avoid clutter\n",
    "        pw_slice = df.iloc[pw[\"start_idx\"]:pw[\"end_idx\"]+1]\n",
    "        ax.plot(pw_slice[\"x\"], pw_slice[\"y\"],\n",
    "                color=\"#facc15\", linewidth=2.5, alpha=0.9, zorder=5,\n",
    "                solid_capstyle=\"round\")\n",
    "\n",
    "ax.set_xlabel(\"X (yards)\", fontsize=11)\n",
    "ax.set_ylabel(\"Y (yards)\", fontsize=11)\n",
    "ax.set_title(\"Movement Trace â€” Colored by Speed Band\", fontsize=13, fontweight=\"bold\", pad=12)\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.grid(True, alpha=0.15)\n",
    "\n",
    "# Legend\n",
    "legend_patches = [mpatches.Patch(color=band_colors[b[\"name\"]], label=b[\"name\"]) for b in SPEED_BANDS]\n",
    "legend_patches.append(plt.Line2D([0], [0], color=\"#facc15\", linewidth=2.5, label=\"Peak Window\"))\n",
    "ax.legend(handles=legend_patches, loc=\"upper right\", fontsize=8, framealpha=0.9)\n",
    "\n",
    "# â”€â”€ Right panel: Heatmap (density) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "ax2 = axes1[1]\n",
    "\n",
    "# Create 2D histogram for position density\n",
    "x_bins = np.linspace(df[\"x\"].min() - 2, df[\"x\"].max() + 2, 80)\n",
    "y_bins = np.linspace(df[\"y\"].min() - 2, df[\"y\"].max() + 2, 80)\n",
    "heatmap, xedges, yedges = np.histogram2d(df[\"x\"], df[\"y\"], bins=[x_bins, y_bins])\n",
    "heatmap = gaussian_filter(heatmap.T, sigma=2)\n",
    "\n",
    "# Custom green-to-red colormap\n",
    "colors_heat = [\"#1a1a2e\", \"#16213e\", \"#0f3460\", \"#e94560\", \"#ffd700\"]\n",
    "cmap = LinearSegmentedColormap.from_list(\"field_heat\", colors_heat, N=256)\n",
    "\n",
    "im = ax2.imshow(\n",
    "    heatmap, origin=\"lower\", aspect=\"equal\",\n",
    "    extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]],\n",
    "    cmap=cmap, interpolation=\"gaussian\",\n",
    ")\n",
    "plt.colorbar(im, ax=ax2, label=\"Time Spent (relative)\", shrink=0.8)\n",
    "\n",
    "ax2.set_xlabel(\"X (yards)\", fontsize=11)\n",
    "ax2.set_ylabel(\"Y (yards)\", fontsize=11)\n",
    "ax2.set_title(\"Position Density Heatmap\", fontsize=13, fontweight=\"bold\", pad=12)\n",
    "ax2.grid(True, alpha=0.1, color=\"white\")\n",
    "\n",
    "fig1.suptitle(\n",
    "    \"WHERE: Spatial Usage and Role Signature\\n\"\n",
    "    f\"Assessment: Skill position (WR/DB) â€” {x_range:.0f}Ã—{y_range:.0f} yd coverage, \"\n",
    "    f\"max {metrics['max_speed_mph']:.1f} mph\",\n",
    "    fontsize=14, fontweight=\"bold\", y=0.98\n",
    ")\n",
    "fig1.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "fig1.savefig(FIG_DIR / \"01_space.png\", dpi=180, bbox_inches=\"tight\", facecolor=\"white\")\n",
    "plt.close(fig1)\n",
    "print(\"  Saved: 01_space.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94a0a28",
   "metadata": {},
   "source": [
    "## STEP 9: FIGURE 2 â€” INTENSITY TIMELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adb944d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 9: Generating Figure 2 â€” Intensity Timeline\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 9: Generating Figure 2 â€” Intensity Timeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4105fd68",
   "metadata": {},
   "source": [
    "## STEP 9: FIGURE 2 â€” INTENSITY TIMELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d4a5426",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_79208\\1987519864.py:86: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  fig2.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: 02_time.png\n"
     ]
    }
   ],
   "source": [
    "fig2 = plt.figure(figsize=(16, 9))\n",
    "gs = gridspec.GridSpec(3, 1, height_ratios=[3, 1, 0.4], hspace=0.08)\n",
    "\n",
    "# â”€â”€ Top panel: Speed over time â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "ax_speed = fig2.add_subplot(gs[0])\n",
    "\n",
    "# Resample to 1-second bins for cleaner plotting\n",
    "df[\"sec_bin\"] = (df[\"elapsed_s\"] // 1).astype(int)\n",
    "sec_agg = df.groupby(\"sec_bin\").agg(\n",
    "    speed_mph=(\"speed_mph\", \"mean\"),\n",
    "    elapsed_min=(\"elapsed_min\", \"mean\"),\n",
    "    step_dist_yd=(\"step_dist_yd\", \"sum\"),\n",
    "    max_speed_mph=(\"speed_mph\", \"max\"),\n",
    ").reset_index()\n",
    "\n",
    "ax_speed.fill_between(\n",
    "    sec_agg[\"elapsed_min\"], sec_agg[\"speed_mph\"],\n",
    "    color=\"#3b82f6\", alpha=0.4, linewidth=0\n",
    ")\n",
    "ax_speed.plot(sec_agg[\"elapsed_min\"], sec_agg[\"speed_mph\"],\n",
    "              color=\"#1d4ed8\", linewidth=0.5, alpha=0.7)\n",
    "\n",
    "# HSR threshold line\n",
    "ax_speed.axhline(HSR_THRESHOLD_MPH, color=\"#ef4444\", linestyle=\"--\", linewidth=1, alpha=0.7, label=f\"HSR ({HSR_THRESHOLD_MPH} mph)\")\n",
    "ax_speed.axhline(SPRINT_THRESHOLD_MPH, color=\"#dc2626\", linestyle=\":\", linewidth=1, alpha=0.5, label=f\"Sprint ({SPRINT_THRESHOLD_MPH} mph)\")\n",
    "\n",
    "# Highlight peak windows\n",
    "pw_colors = [\"#f59e0b\", \"#10b981\", \"#8b5cf6\", \"#ec4899\", \"#06b6d4\"]\n",
    "for i, pw in enumerate(peak_windows):\n",
    "    start_min = pw[\"start_elapsed_min\"]\n",
    "    end_min = pw[\"end_elapsed_min\"]\n",
    "    ax_speed.axvspan(start_min, end_min, alpha=0.15, color=pw_colors[i % len(pw_colors)], zorder=0)\n",
    "    ax_speed.text(\n",
    "        (start_min + end_min) / 2, ax_speed.get_ylim()[1] * 0.95 if i == 0 else ax_speed.get_ylim()[1] * (0.95 - 0.06 * i),\n",
    "        pw[\"window_label\"], ha=\"center\", fontsize=7, fontweight=\"bold\",\n",
    "        color=pw_colors[i % len(pw_colors)], alpha=0.9\n",
    "    )\n",
    "\n",
    "ax_speed.set_ylabel(\"Speed (mph)\", fontsize=11)\n",
    "ax_speed.set_xlim(0, df[\"elapsed_min\"].max())\n",
    "ax_speed.set_ylim(0, metrics[\"max_speed_mph\"] * 1.1)\n",
    "ax_speed.legend(loc=\"upper right\", fontsize=8)\n",
    "ax_speed.set_title(\n",
    "    \"WHEN: Intensity Over Time â€” Speed, Distance Rate, and Session Phases\",\n",
    "    fontsize=14, fontweight=\"bold\", pad=12\n",
    ")\n",
    "ax_speed.tick_params(labelbottom=False)\n",
    "ax_speed.grid(True, alpha=0.15)\n",
    "\n",
    "# â”€â”€ Middle panel: Distance rate (rolling 60s yd/min) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "ax_dist = fig2.add_subplot(gs[1], sharex=ax_speed)\n",
    "\n",
    "# 60-second rolling distance rate\n",
    "roll_60 = sec_agg[\"step_dist_yd\"].rolling(60, min_periods=30).sum()  # yd per 60s = yd/min\n",
    "ax_dist.fill_between(sec_agg[\"elapsed_min\"], roll_60.fillna(0),\n",
    "                      color=\"#10b981\", alpha=0.4, linewidth=0)\n",
    "ax_dist.plot(sec_agg[\"elapsed_min\"], roll_60, color=\"#059669\", linewidth=0.8)\n",
    "ax_dist.set_ylabel(\"Distance Rate\\n(yd/min, 60s window)\", fontsize=9)\n",
    "ax_dist.set_ylim(0, roll_60.max() * 1.2 if roll_60.max() > 0 else 10)\n",
    "ax_dist.tick_params(labelbottom=False)\n",
    "ax_dist.grid(True, alpha=0.15)\n",
    "\n",
    "# â”€â”€ Bottom panel: Phase strip â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "ax_phase = fig2.add_subplot(gs[2], sharex=ax_speed)\n",
    "\n",
    "intensity_colors = {\n",
    "    \"Rest\": \"#e5e7eb\",\n",
    "    \"Low\": \"#93c5fd\",\n",
    "    \"Moderate\": \"#60a5fa\",\n",
    "    \"Moderate-High\": \"#f59e0b\",\n",
    "    \"High\": \"#ef4444\",\n",
    "}\n",
    "\n",
    "for _, p in phase_df_summary.iterrows():\n",
    "    color = intensity_colors.get(p[\"intensity\"], \"#d1d5db\")\n",
    "    ax_phase.axvspan(p[\"start_min\"], p[\"end_min\"], color=color, alpha=0.8)\n",
    "\n",
    "ax_phase.set_xlabel(\"Elapsed Time (minutes)\", fontsize=11)\n",
    "ax_phase.set_yticks([])\n",
    "ax_phase.set_ylabel(\"Phase\", fontsize=9, rotation=0, labelpad=35)\n",
    "\n",
    "# Phase legend\n",
    "phase_patches = [mpatches.Patch(color=c, label=l) for l, c in intensity_colors.items()]\n",
    "ax_phase.legend(handles=phase_patches, loc=\"upper right\", fontsize=7, ncol=5, framealpha=0.9)\n",
    "\n",
    "fig2.tight_layout()\n",
    "fig2.savefig(FIG_DIR / \"02_time.png\", dpi=180, bbox_inches=\"tight\", facecolor=\"white\")\n",
    "plt.close(fig2)\n",
    "print(\"  Saved: 02_time.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc527a61",
   "metadata": {},
   "source": [
    "## STEP 10: FIGURE 3 â€” PEAK DEMAND PROFILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f4c4473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 10: Generating Figure 3 â€” Peak Demand Profile\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 10: Generating Figure 3 â€” Peak Demand Profile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aef0382",
   "metadata": {},
   "source": [
    "## STEP 10: FIGURE 3 â€” PEAK DEMAND PROFILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3188129b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: 03_peaks.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_79208\\3587759521.py:58: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  fig3.tight_layout(rect=[0, 0, 1, 0.93])\n"
     ]
    }
   ],
   "source": [
    "fig3 = plt.figure(figsize=(16, 8))\n",
    "gs3 = gridspec.GridSpec(1, 2, width_ratios=[1.3, 1], wspace=0.3)\n",
    "\n",
    "# â”€â”€ Left panel: Peak intensity curve (yd/min vs duration) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "ax_peak = fig3.add_subplot(gs3[0])\n",
    "\n",
    "if len(peak_windows_df) > 0:\n",
    "    ax_peak.plot(\n",
    "        peak_windows_df[\"window_s\"],\n",
    "        peak_windows_df[\"intensity_yd_min\"],\n",
    "        color=\"#1d4ed8\", linewidth=2.5, marker=\"o\", markersize=8,\n",
    "        markerfacecolor=\"#3b82f6\", markeredgecolor=\"white\", markeredgewidth=2,\n",
    "        zorder=3,\n",
    "    )\n",
    "    # Annotate each point\n",
    "    for _, pw in peak_windows_df.iterrows():\n",
    "        ax_peak.annotate(\n",
    "            f\"{pw['intensity_yd_min']:.0f}\\nyd/min\",\n",
    "            (pw[\"window_s\"], pw[\"intensity_yd_min\"]),\n",
    "            textcoords=\"offset points\", xytext=(0, 15),\n",
    "            ha=\"center\", fontsize=9, fontweight=\"bold\", color=\"#1e3a5f\",\n",
    "        )\n",
    "\n",
    "ax_peak.set_xlabel(\"Window Duration (seconds)\", fontsize=12)\n",
    "ax_peak.set_ylabel(\"Peak Intensity (yd/min)\", fontsize=12)\n",
    "ax_peak.set_title(\"Peak Demand Curve\", fontsize=13, fontweight=\"bold\")\n",
    "ax_peak.set_xticks([pw[\"window_s\"] for pw in peak_windows])\n",
    "ax_peak.set_xticklabels([pw[\"window_label\"] for pw in peak_windows])\n",
    "ax_peak.grid(True, alpha=0.2)\n",
    "ax_peak.set_ylim(0, peak_windows_df[\"intensity_yd_min\"].max() * 1.3 if len(peak_windows_df) > 0 else 100)\n",
    "\n",
    "# â”€â”€ Right panel: Speed band distance breakdown â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "ax_bands = fig3.add_subplot(gs3[1])\n",
    "\n",
    "band_names = [b[\"name\"] for b in SPEED_BANDS]\n",
    "band_dists = [speed_band_dist.loc[bn, \"distance_yd\"] if bn in speed_band_dist.index else 0 for bn in band_names]\n",
    "band_cols = [band_colors.get(bn, \"#999\") for bn in band_names]\n",
    "\n",
    "bars = ax_bands.barh(band_names, band_dists, color=band_cols, edgecolor=\"white\", linewidth=0.5)\n",
    "\n",
    "for bar, dist in zip(bars, band_dists):\n",
    "    if dist > 0:\n",
    "        pct = dist / total_distance_yd * 100\n",
    "        ax_bands.text(bar.get_width() + 5, bar.get_y() + bar.get_height() / 2,\n",
    "                      f\"{dist:.0f} yd ({pct:.1f}%)\",\n",
    "                      va=\"center\", fontsize=9, fontweight=\"bold\")\n",
    "\n",
    "ax_bands.set_xlabel(\"Distance (yards)\", fontsize=12)\n",
    "ax_bands.set_title(\"Distance by Speed Band\", fontsize=13, fontweight=\"bold\")\n",
    "ax_bands.grid(True, axis=\"x\", alpha=0.2)\n",
    "ax_bands.invert_yaxis()\n",
    "\n",
    "fig3.suptitle(\n",
    "    f\"WHAT: Peak Demands â€” Total Distance {total_distance_yd:.0f} yd | \"\n",
    "    f\"HSR {metrics['hsr_distance_yd']} yd | Sprint {metrics['sprint_distance_yd']} yd\",\n",
    "    fontsize=14, fontweight=\"bold\", y=0.98,\n",
    ")\n",
    "fig3.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "fig3.savefig(FIG_DIR / \"03_peaks.png\", dpi=180, bbox_inches=\"tight\", facecolor=\"white\")\n",
    "plt.close(fig3)\n",
    "print(\"  Saved: 03_peaks.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd65a58f",
   "metadata": {},
   "source": [
    "## STEP 11: EXPORT TABLES AND RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44735344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 11: Exporting tables and results contract\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 11: Exporting tables and results contract\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dadfa5",
   "metadata": {},
   "source": [
    "## STEP 11: EXPORT TABLES AND RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbf2a432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: speed_band_summary.csv\n",
      "  Saved: peak_windows.csv\n",
      "  Saved: phase_summary.csv\n",
      "  Saved: early_vs_late.csv\n",
      "  Saved: event_counts.csv\n",
      "  Saved: session_metrics.csv\n",
      "  Saved: qc_summary.csv\n",
      "  âœ“ Results saved: C:\\docker_projects\\browns_performance_science_fellowship\\outputs\\results.json\n",
      "\n",
      "======================================================================\n",
      "PIPELINE COMPLETE\n"
     ]
    }
   ],
   "source": [
    "# Speed band table\n",
    "speed_band_export = speed_band_dist.reset_index()\n",
    "speed_band_export.columns = [\"Zone\", \"Distance (yd)\", \"Samples\", \"Time (s)\", \"Distance (%)\", \"Time (min)\", \"Time (%)\"]\n",
    "speed_band_export.to_csv(TABLE_DIR / \"speed_band_summary.csv\", index=False)\n",
    "print(\"  Saved: speed_band_summary.csv\")\n",
    "\n",
    "# Peak windows table\n",
    "peak_windows_df.to_csv(TABLE_DIR / \"peak_windows.csv\", index=False)\n",
    "print(\"  Saved: peak_windows.csv\")\n",
    "\n",
    "# Phase summary table\n",
    "phase_df_summary.to_csv(TABLE_DIR / \"phase_summary.csv\", index=False)\n",
    "print(\"  Saved: phase_summary.csv\")\n",
    "\n",
    "# Early vs late table\n",
    "early_late_df.to_csv(TABLE_DIR / \"early_vs_late.csv\", index=False)\n",
    "print(\"  Saved: early_vs_late.csv\")\n",
    "\n",
    "# Event counts table\n",
    "pd.DataFrame([event_counts]).to_csv(TABLE_DIR / \"event_counts.csv\", index=False)\n",
    "print(\"  Saved: event_counts.csv\")\n",
    "\n",
    "# Session metrics\n",
    "pd.DataFrame([metrics]).to_csv(TABLE_DIR / \"session_metrics.csv\", index=False)\n",
    "print(\"  Saved: session_metrics.csv\")\n",
    "\n",
    "# QC summary\n",
    "pd.DataFrame([qc_summary]).to_csv(TABLE_DIR / \"qc_summary.csv\", index=False)\n",
    "print(\"  Saved: qc_summary.csv\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Results contract (JSON) â€” with NumPy type conversion\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "contract = {\n",
    "    \"session_summary\": {**qc_summary, **metrics, **event_counts},\n",
    "    \"thresholds\": {\n",
    "        \"speed_bands_mph\": SPEED_BANDS,\n",
    "        \"hsr_threshold_mph\": HSR_THRESHOLD_MPH,\n",
    "        \"sprint_threshold_mph\": SPRINT_THRESHOLD_MPH,\n",
    "        \"accel_threshold_ms2\": ACCEL_THRESHOLD_MS2,\n",
    "        \"decel_threshold_ms2\": DECEL_THRESHOLD_MS2,\n",
    "    },\n",
    "    \"units\": {\n",
    "        \"distance\": \"yards\",\n",
    "        \"speed\": \"mph\",\n",
    "        \"acceleration\": \"m/sÂ²\",\n",
    "        \"speed_conversion\": {\"from\": \"yd/s\", \"to\": \"mph\", \"factor\": YDS_TO_MPH},\n",
    "        \"accel_conversion\": {\"from\": \"yd/sÂ²\", \"to\": \"m/sÂ²\", \"factor\": YDS2_TO_MS2},\n",
    "    },\n",
    "    \"peak_windows\": peak_windows,\n",
    "    \"early_vs_late_delta_pct\": dist_delta_pct,\n",
    "    \"figures\": {\n",
    "        \"01_space\": str(FIG_DIR / \"01_space.png\"),\n",
    "        \"02_time\": str(FIG_DIR / \"02_time.png\"),\n",
    "        \"03_peaks\": str(FIG_DIR / \"03_peaks.png\"),\n",
    "    },\n",
    "}\n",
    "\n",
    "# Convert all NumPy types to Python native types before JSON serialization\n",
    "contract_clean = convert_numpy_to_python(contract)\n",
    "\n",
    "# Save to JSON\n",
    "results_path = OUT_DIR / \"results.json\"\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(contract_clean, f, indent=2)\n",
    "\n",
    "print(f\"  âœ“ Results saved: {results_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PIPELINE COMPLETE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eb05e6",
   "metadata": {},
   "source": [
    "## STEP 11: EXPORT TABLES AND RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "670a7c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All outputs in: C:\\docker_projects\\browns_performance_science_fellowship\\outputs\n",
      "Figures: [WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/figures/01_space.png'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/figures/02_time.png'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/figures/03_peaks.png'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/figures/coach_slide_intensity_timeline.png'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/figures/coach_slide_movement_map.png'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/figures/coach_slide_peak_demand_summary.png')]\n",
      "Tables: [WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/absolute_speed_band_summary.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/analysis_df.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/coach_phase_summary.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/data_quality_summary.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/early_late_comparison.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/early_vs_late.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/early_vs_late_summary.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/event_counts.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/final_deck_outline.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/metrics_summary.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/peak_by_duration.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/peak_distance_windows.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/peak_windows.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/phase_summary.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/qc_checks.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/qc_summary.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/raw_segment_boundaries.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/raw_segment_summary.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/relative_speed_band_summary.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/segment_boundaries.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/segment_summary.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/session_event_counts.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/session_extrema.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/session_metrics.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/session_structure_map.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/slide_1_data_quality_table.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/slide_1_qc_checks_table.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/slide_1_validation_gates_table.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/slide_2_speed_zone_table.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/slide_3_event_counts_table.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/slide_3_extrema_table.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/slide_3_peak_distance_table.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/slide_3_top_windows_table.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/slide_4_segment_table.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/slide_4_structure_map_table.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/slide_5_early_late_table.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/speed_bands.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/speed_band_summary.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/top_1m_distance_windows.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/top_windows_by_duration.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/validation_gates.csv'), WindowsPath('C:/docker_projects/browns_performance_science_fellowship/outputs/tables/viz_df.csv')]\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nAll outputs in: {OUT_DIR}\")\n",
    "print(f\"Figures: {list(FIG_DIR.glob('*.png'))}\")\n",
    "print(f\"Tables: {list(TABLE_DIR.glob('*.csv'))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "browns-performance-science-fellowship (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
