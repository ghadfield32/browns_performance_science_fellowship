{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b03c477",
   "metadata": {},
   "source": [
    "# Browns Performance Science — Tracking Analysis\n",
    "\n",
    "**Single anonymized practice session (10 Hz tracking data)**\n",
    "\n",
    "This notebook is the complete, self-contained analysis pipeline. It loads raw CSV data, performs quality control, computes all workload metrics, detects session phases, and generates three coach-ready visualizations.\n",
    "\n",
    "**Units (hard requirement):**\n",
    "- Distance: yards\n",
    "- Speed: miles per hour (mph)\n",
    "- Acceleration/Deceleration: m/s²\n",
    "\n",
    "**Conversion factors:**\n",
    "- yd/s → mph: × 3600/1760 ≈ 2.04545\n",
    "- yd/s² → m/s²: × 0.9144\n",
    "\n",
    "**Distance policy:** Speed-derived step distance (`s × dt`) is the primary distance metric. XY displacement corroborates (r = 0.979). Vendor `dis` column is unreliable and used only for QA cross-check.\n",
    "\n",
    "**Continuity policy:** Rolling windows, events, and trajectory lines reset at flagged gaps (>1s) and improbable jumps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceabe57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Browns Performance Science Fellow — Tracking Analysis Pipeline\n",
    "==============================================================\n",
    "Single-player anonymized practice session (10 Hz tracking data).\n",
    "\n",
    "Units (hard requirement):\n",
    "  - Distance: yards\n",
    "  - Speed: miles per hour (mph)\n",
    "  - Acceleration/Deceleration: m/s²\n",
    "\n",
    "Conversion factors:\n",
    "  - yd/s → mph:  multiply by 3600/1760 ≈ 2.045454545\n",
    "  - yd/s² → m/s²: multiply by 0.9144\n",
    "\n",
    "Author: Geoff\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# ── Paths ────────────────────────────────────────────────────────────────\n",
    "DATA_PATH = Path(\"/mnt/user-data/uploads/tracking_data.csv\")\n",
    "OUT_DIR = Path(\"/home/claude/outputs\")\n",
    "FIG_DIR = OUT_DIR / \"figures\"\n",
    "TABLE_DIR = OUT_DIR / \"tables\"\n",
    "for d in [FIG_DIR, TABLE_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ── Constants ────────────────────────────────────────────────────────────\n",
    "YDS_TO_MPH = 3600.0 / 1760.0        # 2.045454545...\n",
    "YDS2_TO_MS2 = 0.9144\n",
    "EXPECTED_CADENCE_S = 0.1\n",
    "GAP_THRESHOLD_S = 1.0                # flag gaps > 1 second\n",
    "TELEPORT_SPEED_YDS = 25.0            # yd/s (~51 mph) – impossible for humans\n",
    "\n",
    "# Speed band definitions (mph) — justified by NFL tracking conventions\n",
    "SPEED_BANDS = [\n",
    "    {\"name\": \"Standing\",    \"lower\": 0.0,  \"upper\": 1.0},\n",
    "    {\"name\": \"Walking\",     \"lower\": 1.0,  \"upper\": 4.0},\n",
    "    {\"name\": \"Jogging\",     \"lower\": 4.0,  \"upper\": 8.0},\n",
    "    {\"name\": \"Running\",     \"lower\": 8.0,  \"upper\": 13.0},\n",
    "    {\"name\": \"High-Speed\",  \"lower\": 13.0, \"upper\": 16.0},\n",
    "    {\"name\": \"Sprint\",      \"lower\": 16.0, \"upper\": None},\n",
    "]\n",
    "\n",
    "HSR_THRESHOLD_MPH = 13.0\n",
    "SPRINT_THRESHOLD_MPH = 16.0\n",
    "ACCEL_THRESHOLD_MS2 = 2.0     # ≥2.0 m/s² = high accel event\n",
    "DECEL_THRESHOLD_MS2 = -2.0   # ≤-2.0 m/s² = high decel event\n",
    "\n",
    "# Rolling window durations for peak demand analysis\n",
    "PEAK_WINDOWS_S = [15, 30, 60, 120, 300]\n",
    "\n",
    "# Phase detection parameters\n",
    "PHASE_BIN_S = 120            # 2-minute bins for phase detection\n",
    "PHASE_MERGE_GAP_MIN = 2.0   # merge rest blocks shorter than 2 min into adjacent active\n",
    "MIN_ACTIVE_SPEED_MPH = 1.5  # speed threshold for \"active\" classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798b9535",
   "metadata": {},
   "source": [
    "## STEP 1: LOAD AND QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec9a9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"STEP 1: Load raw data and quality control\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a72a480",
   "metadata": {},
   "source": [
    "## STEP 1: LOAD AND QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64edcb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv(DATA_PATH)\n",
    "raw[\"ts\"] = pd.to_datetime(raw[\"ts\"], utc=True)\n",
    "raw = raw.sort_values(\"ts\").reset_index(drop=True)\n",
    "\n",
    "# Compute dt (time delta between consecutive samples)\n",
    "raw[\"dt\"] = raw[\"ts\"].diff().dt.total_seconds()\n",
    "raw.loc[0, \"dt\"] = EXPECTED_CADENCE_S  # first row has no predecessor\n",
    "\n",
    "# ── QC: Timestamp gaps ───────────────────────────────────────────────────\n",
    "gap_mask = raw[\"dt\"] > GAP_THRESHOLD_S\n",
    "gap_count = gap_mask.sum()\n",
    "max_gap_s = raw[\"dt\"].max()\n",
    "pct_on_cadence = ((raw[\"dt\"] - EXPECTED_CADENCE_S).abs() < 0.02).mean() * 100\n",
    "\n",
    "print(f\"  Rows: {len(raw):,}\")\n",
    "print(f\"  Time span: {raw['ts'].iloc[0]} → {raw['ts'].iloc[-1]}\")\n",
    "print(f\"  Duration: {(raw['ts'].iloc[-1] - raw['ts'].iloc[0]).total_seconds():.1f}s \"\n",
    "      f\"({(raw['ts'].iloc[-1] - raw['ts'].iloc[0]).total_seconds()/60:.1f} min)\")\n",
    "print(f\"  Cadence: {pct_on_cadence:.1f}% of samples at expected 0.1s\")\n",
    "print(f\"  Gaps > {GAP_THRESHOLD_S}s: {gap_count} (max: {max_gap_s:.1f}s)\")\n",
    "\n",
    "# ── QC: Flag gaps and teleports ──────────────────────────────────────────\n",
    "raw[\"is_gap\"] = gap_mask\n",
    "\n",
    "# XY displacement check\n",
    "raw[\"xy_step\"] = np.sqrt(raw[\"x\"].diff()**2 + raw[\"y\"].diff()**2)\n",
    "raw[\"xy_speed_yds\"] = raw[\"xy_step\"] / raw[\"dt\"].replace(0, np.nan)\n",
    "teleport_mask = raw[\"xy_speed_yds\"] > TELEPORT_SPEED_YDS\n",
    "raw[\"is_teleport\"] = teleport_mask\n",
    "print(f\"  Teleport samples (>{TELEPORT_SPEED_YDS} yd/s): {teleport_mask.sum()}\")\n",
    "\n",
    "# ── QC: Speed-vs-XY consistency ──────────────────────────────────────────\n",
    "normal = ~raw[\"is_gap\"] & ~raw[\"is_teleport\"] & (raw[\"dt\"] > 0)\n",
    "if normal.sum() > 100:\n",
    "    speed_xy_corr = np.corrcoef(\n",
    "        raw.loc[normal, \"s\"],\n",
    "        raw.loc[normal, \"xy_speed_yds\"].fillna(0)\n",
    "    )[0, 1]\n",
    "    print(f\"  Speed vs XY-derived speed correlation: {speed_xy_corr:.3f}\")\n",
    "\n",
    "# ── QC: dis column validation ────────────────────────────────────────────\n",
    "dist_speed = (raw[\"s\"] * raw[\"dt\"]).sum()\n",
    "dist_xy = raw[\"xy_step\"].sum()\n",
    "dist_dis = raw[\"dis\"].sum()\n",
    "print(f\"  Distance from speed*dt: {dist_speed:.1f} yd\")\n",
    "print(f\"  Distance from XY displacement: {dist_xy:.1f} yd\")\n",
    "print(f\"  Distance from 'dis' column: {dist_dis:.1f} yd (vendor — unreliable, not used)\")\n",
    "\n",
    "# Assign continuity block IDs (reset at gaps)\n",
    "raw[\"block_id\"] = raw[\"is_gap\"].cumsum()\n",
    "\n",
    "# ── QC Summary table ─────────────────────────────────────────────────────\n",
    "qc_summary = {\n",
    "    \"total_rows\": len(raw),\n",
    "    \"session_start_utc\": str(raw[\"ts\"].iloc[0]),\n",
    "    \"session_end_utc\": str(raw[\"ts\"].iloc[-1]),\n",
    "    \"duration_s\": round((raw[\"ts\"].iloc[-1] - raw[\"ts\"].iloc[0]).total_seconds(), 1),\n",
    "    \"pct_at_expected_cadence\": round(pct_on_cadence, 2),\n",
    "    \"gap_count\": int(gap_count),\n",
    "    \"max_gap_s\": round(max_gap_s, 2),\n",
    "    \"teleport_count\": int(teleport_mask.sum()),\n",
    "    \"continuity_blocks\": int(raw[\"block_id\"].nunique()),\n",
    "    \"distance_speed_yd\": round(dist_speed, 1),\n",
    "    \"distance_xy_yd\": round(dist_xy, 1),\n",
    "    \"distance_dis_yd\": round(dist_dis, 1),\n",
    "    \"speed_xy_correlation\": round(speed_xy_corr, 3) if normal.sum() > 100 else None,\n",
    "    \"qc_status\": \"PASS\" if gap_count <= 10 and pct_on_cadence > 95 else \"WARN\",\n",
    "}\n",
    "print(f\"\\n  QC Status: {qc_summary['qc_status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917d4703",
   "metadata": {},
   "source": [
    "## STEP 2: UNIT CONVERSIONS AND DERIVED COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee03e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 2: Unit conversions and derived columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6868dc27",
   "metadata": {},
   "source": [
    "## STEP 2: UNIT CONVERSIONS AND DERIVED COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40931913",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw.copy()\n",
    "\n",
    "# Speed: yd/s → mph\n",
    "df[\"speed_mph\"] = df[\"s\"] * YDS_TO_MPH\n",
    "\n",
    "# Acceleration: yd/s² → m/s² (using signed sa for accel/decel direction)\n",
    "df[\"accel_ms2\"] = df[\"sa\"] * YDS2_TO_MS2\n",
    "df[\"accel_mag_ms2\"] = df[\"a\"] * YDS2_TO_MS2\n",
    "\n",
    "# Step distance (speed-derived, yards)\n",
    "df[\"step_dist_yd\"] = df[\"s\"] * df[\"dt\"]\n",
    "# Zero out step distance at gaps (don't accumulate distance across discontinuities)\n",
    "df.loc[df[\"is_gap\"], \"step_dist_yd\"] = 0.0\n",
    "\n",
    "# Elapsed time (seconds and minutes from session start)\n",
    "df[\"elapsed_s\"] = (df[\"ts\"] - df[\"ts\"].iloc[0]).dt.total_seconds()\n",
    "df[\"elapsed_min\"] = df[\"elapsed_s\"] / 60.0\n",
    "\n",
    "# Speed band classification\n",
    "def classify_speed_band(speed_mph):\n",
    "    for band in SPEED_BANDS:\n",
    "        upper = band[\"upper\"] if band[\"upper\"] is not None else np.inf\n",
    "        if band[\"lower\"] <= speed_mph < upper:\n",
    "            return band[\"name\"]\n",
    "    return SPEED_BANDS[-1][\"name\"]\n",
    "\n",
    "df[\"speed_band\"] = df[\"speed_mph\"].apply(classify_speed_band)\n",
    "\n",
    "# HSR / Sprint flags\n",
    "df[\"is_hsr\"] = df[\"speed_mph\"] >= HSR_THRESHOLD_MPH\n",
    "df[\"is_sprint\"] = df[\"speed_mph\"] >= SPRINT_THRESHOLD_MPH\n",
    "df[\"is_accel\"] = df[\"accel_ms2\"] >= ACCEL_THRESHOLD_MS2\n",
    "df[\"is_decel\"] = df[\"accel_ms2\"] <= DECEL_THRESHOLD_MS2\n",
    "\n",
    "print(f\"  Conversion: yd/s → mph (factor: {YDS_TO_MPH:.6f})\")\n",
    "print(f\"  Conversion: yd/s² → m/s² (factor: {YDS2_TO_MS2})\")\n",
    "print(f\"  Speed bands: {', '.join(b['name'] for b in SPEED_BANDS)}\")\n",
    "print(f\"  HSR threshold: {HSR_THRESHOLD_MPH} mph | Sprint: {SPRINT_THRESHOLD_MPH} mph\")\n",
    "print(f\"  Accel threshold: {ACCEL_THRESHOLD_MS2} m/s² | Decel: {DECEL_THRESHOLD_MS2} m/s²\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455e15a5",
   "metadata": {},
   "source": [
    "## STEP 3: SESSION-LEVEL METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07ce9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 3: Session-level workload metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1c6ddb",
   "metadata": {},
   "source": [
    "## STEP 3: SESSION-LEVEL METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481fa973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 3a: Total distance ───────────────────────────────────────────────────\n",
    "total_distance_yd = df[\"step_dist_yd\"].sum()\n",
    "print(f\"  Total distance: {total_distance_yd:.1f} yd\")\n",
    "\n",
    "# ── 3b: Distance by speed band ───────────────────────────────────────────\n",
    "speed_band_dist = df.groupby(\"speed_band\").agg(\n",
    "    distance_yd=(\"step_dist_yd\", \"sum\"),\n",
    "    sample_count=(\"step_dist_yd\", \"count\"),\n",
    "    time_s=(\"dt\", \"sum\"),\n",
    ").reindex([b[\"name\"] for b in SPEED_BANDS]).fillna(0)\n",
    "\n",
    "speed_band_dist[\"distance_pct\"] = (speed_band_dist[\"distance_yd\"] / total_distance_yd * 100).round(1)\n",
    "speed_band_dist[\"time_min\"] = (speed_band_dist[\"time_s\"] / 60).round(1)\n",
    "speed_band_dist[\"time_pct\"] = (speed_band_dist[\"time_s\"] / df[\"dt\"].sum() * 100).round(1)\n",
    "\n",
    "print(\"\\n  Speed Band Distance Breakdown:\")\n",
    "for band_name, row in speed_band_dist.iterrows():\n",
    "    print(f\"    {band_name:12s}: {row['distance_yd']:7.1f} yd ({row['distance_pct']:5.1f}%)  \"\n",
    "          f\"| {row['time_min']:5.1f} min ({row['time_pct']:5.1f}%)\")\n",
    "\n",
    "# ── 3c: Speed and acceleration statistics ────────────────────────────────\n",
    "metrics = {\n",
    "    \"total_distance_yd\": round(total_distance_yd, 1),\n",
    "    \"mean_speed_mph\": round(df[\"speed_mph\"].mean(), 2),\n",
    "    \"median_speed_mph\": round(df[\"speed_mph\"].median(), 2),\n",
    "    \"p95_speed_mph\": round(df[\"speed_mph\"].quantile(0.95), 2),\n",
    "    \"max_speed_mph\": round(df[\"speed_mph\"].max(), 2),\n",
    "    \"mean_accel_ms2\": round(df[\"accel_ms2\"].mean(), 3),\n",
    "    \"peak_accel_ms2\": round(df[\"accel_ms2\"].max(), 2),\n",
    "    \"peak_decel_ms2\": round(df[\"accel_ms2\"].min(), 2),\n",
    "    \"p95_accel_ms2\": round(df[\"accel_ms2\"].quantile(0.99), 2),\n",
    "    \"p05_decel_ms2\": round(df[\"accel_ms2\"].quantile(0.01), 2),\n",
    "    \"hsr_distance_yd\": round(df.loc[df[\"is_hsr\"], \"step_dist_yd\"].sum(), 1),\n",
    "    \"sprint_distance_yd\": round(df.loc[df[\"is_sprint\"], \"step_dist_yd\"].sum(), 1),\n",
    "    \"hsr_time_s\": round(df.loc[df[\"is_hsr\"], \"dt\"].sum(), 1),\n",
    "    \"sprint_time_s\": round(df.loc[df[\"is_sprint\"], \"dt\"].sum(), 1),\n",
    "}\n",
    "\n",
    "print(f\"\\n  Mean speed: {metrics['mean_speed_mph']} mph\")\n",
    "print(f\"  Median speed: {metrics['median_speed_mph']} mph\")\n",
    "print(f\"  P95 speed: {metrics['p95_speed_mph']} mph\")\n",
    "print(f\"  Max speed: {metrics['max_speed_mph']} mph\")\n",
    "print(f\"  Peak accel: {metrics['peak_accel_ms2']} m/s²\")\n",
    "print(f\"  Peak decel: {metrics['peak_decel_ms2']} m/s²\")\n",
    "print(f\"  HSR distance: {metrics['hsr_distance_yd']} yd ({metrics['hsr_time_s']}s)\")\n",
    "print(f\"  Sprint distance: {metrics['sprint_distance_yd']} yd ({metrics['sprint_time_s']}s)\")\n",
    "\n",
    "# ── 3d: Event detection (contiguous threshold exposure >= 1s) ─────────────\n",
    "def count_events(mask, dt_series, min_duration_s=1.0):\n",
    "    \"\"\"Count contiguous True runs lasting >= min_duration_s.\"\"\"\n",
    "    events = []\n",
    "    in_event = False\n",
    "    event_start = 0\n",
    "    event_duration = 0.0\n",
    "    event_distance = 0.0\n",
    "    for i in range(len(mask)):\n",
    "        if mask.iloc[i]:\n",
    "            if not in_event:\n",
    "                in_event = True\n",
    "                event_start = i\n",
    "                event_duration = 0.0\n",
    "                event_distance = 0.0\n",
    "            event_duration += dt_series.iloc[i]\n",
    "            event_distance += df[\"step_dist_yd\"].iloc[i]\n",
    "        else:\n",
    "            if in_event:\n",
    "                if event_duration >= min_duration_s:\n",
    "                    events.append({\n",
    "                        \"start_idx\": event_start,\n",
    "                        \"end_idx\": i - 1,\n",
    "                        \"duration_s\": round(event_duration, 2),\n",
    "                        \"distance_yd\": round(event_distance, 1),\n",
    "                    })\n",
    "                in_event = False\n",
    "    # Handle event running to end\n",
    "    if in_event and event_duration >= min_duration_s:\n",
    "        events.append({\n",
    "            \"start_idx\": event_start,\n",
    "            \"end_idx\": len(mask) - 1,\n",
    "            \"duration_s\": round(event_duration, 2),\n",
    "            \"distance_yd\": round(event_distance, 1),\n",
    "        })\n",
    "    return events\n",
    "\n",
    "hsr_events = count_events(df[\"is_hsr\"], df[\"dt\"])\n",
    "sprint_events = count_events(df[\"is_sprint\"], df[\"dt\"])\n",
    "accel_events = count_events(df[\"is_accel\"], df[\"dt\"])\n",
    "decel_events = count_events(df[\"is_decel\"], df[\"dt\"])\n",
    "\n",
    "event_counts = {\n",
    "    \"hsr_event_count\": len(hsr_events),\n",
    "    \"sprint_event_count\": len(sprint_events),\n",
    "    \"accel_event_count\": len(accel_events),\n",
    "    \"decel_event_count\": len(decel_events),\n",
    "    \"hsr_total_distance_yd\": round(sum(e[\"distance_yd\"] for e in hsr_events), 1),\n",
    "    \"sprint_total_distance_yd\": round(sum(e[\"distance_yd\"] for e in sprint_events), 1),\n",
    "}\n",
    "print(f\"\\n  HSR events (≥1s): {event_counts['hsr_event_count']}\")\n",
    "print(f\"  Sprint events (≥1s): {event_counts['sprint_event_count']}\")\n",
    "print(f\"  Accel events (≥{ACCEL_THRESHOLD_MS2} m/s², ≥1s): {event_counts['accel_event_count']}\")\n",
    "print(f\"  Decel events (≤{DECEL_THRESHOLD_MS2} m/s², ≥1s): {event_counts['decel_event_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b5bcb1",
   "metadata": {},
   "source": [
    "## STEP 4: PEAK DEMAND — ROLLING WINDOWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb7da69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 4: Peak demand rolling windows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e162d4",
   "metadata": {},
   "source": [
    "## STEP 4: PEAK DEMAND — ROLLING WINDOWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86d635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each window duration, find the top-1 window by distance (intensity = yd/min)\n",
    "# Windows must not span a gap boundary.\n",
    "peak_windows = []\n",
    "\n",
    "for window_s in PEAK_WINDOWS_S:\n",
    "    window_samples = int(window_s / EXPECTED_CADENCE_S)\n",
    "    best_dist = 0\n",
    "    best_start = 0\n",
    "\n",
    "    # Rolling sum of step distance\n",
    "    roll_dist = df[\"step_dist_yd\"].rolling(window_samples, min_periods=window_samples).sum()\n",
    "    # Rolling count of gaps within window (invalidate windows that span gaps)\n",
    "    roll_gaps = df[\"is_gap\"].astype(int).rolling(window_samples, min_periods=window_samples).sum()\n",
    "\n",
    "    valid = (roll_gaps == 0) & roll_dist.notna()\n",
    "    if valid.any():\n",
    "        best_idx = roll_dist[valid].idxmax()\n",
    "        best_dist = roll_dist[best_idx]\n",
    "        window_start_idx = best_idx - window_samples + 1\n",
    "\n",
    "        peak_windows.append({\n",
    "            \"window_s\": window_s,\n",
    "            \"window_label\": f\"{window_s // 60}min\" if window_s >= 60 else f\"{window_s}s\",\n",
    "            \"distance_yd\": round(best_dist, 1),\n",
    "            \"intensity_yd_min\": round(best_dist / (window_s / 60), 1),\n",
    "            \"start_idx\": int(window_start_idx),\n",
    "            \"end_idx\": int(best_idx),\n",
    "            \"start_utc\": str(df.loc[window_start_idx, \"ts\"]),\n",
    "            \"end_utc\": str(df.loc[best_idx, \"ts\"]),\n",
    "            \"start_elapsed_min\": round(df.loc[window_start_idx, \"elapsed_min\"], 1),\n",
    "            \"end_elapsed_min\": round(df.loc[best_idx, \"elapsed_min\"], 1),\n",
    "            \"mean_speed_mph\": round(df.loc[window_start_idx:best_idx, \"speed_mph\"].mean(), 2),\n",
    "            \"max_speed_mph\": round(df.loc[window_start_idx:best_idx, \"speed_mph\"].max(), 2),\n",
    "        })\n",
    "\n",
    "        label = f\"{window_s // 60}min\" if window_s >= 60 else f\"{window_s}s\"\n",
    "        print(f\"  Best {label:4s}: {best_dist:7.1f} yd ({best_dist / (window_s / 60):6.1f} yd/min) \"\n",
    "              f\"@ min {df.loc[window_start_idx, 'elapsed_min']:.0f}–{df.loc[best_idx, 'elapsed_min']:.0f}\")\n",
    "\n",
    "peak_windows_df = pd.DataFrame(peak_windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c46c4f",
   "metadata": {},
   "source": [
    "## STEP 5: SESSION PHASE SEGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3aec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 5: Session phase segmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f66b77",
   "metadata": {},
   "source": [
    "## STEP 5: SESSION PHASE SEGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99f9e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample into 2-minute bins for phase detection (reduces noise)\n",
    "bin_s = PHASE_BIN_S\n",
    "df[\"bin_phase\"] = (df[\"elapsed_s\"] // bin_s).astype(int)\n",
    "bin_stats = df.groupby(\"bin_phase\").agg(\n",
    "    mean_speed_mph=(\"speed_mph\", \"mean\"),\n",
    "    max_speed_mph=(\"speed_mph\", \"max\"),\n",
    "    distance_yd=(\"step_dist_yd\", \"sum\"),\n",
    "    elapsed_min=(\"elapsed_min\", \"first\"),\n",
    "    sample_count=(\"speed_mph\", \"count\"),\n",
    ").reset_index()\n",
    "\n",
    "# Classify each bin as active or rest\n",
    "bin_stats[\"is_active\"] = bin_stats[\"mean_speed_mph\"] > MIN_ACTIVE_SPEED_MPH\n",
    "\n",
    "# Merge adjacent bins of same type into phases\n",
    "phases = []\n",
    "current_type = None\n",
    "current_start_min = 0\n",
    "current_bins = []\n",
    "\n",
    "for _, brow in bin_stats.iterrows():\n",
    "    btype = \"Active\" if brow[\"is_active\"] else \"Rest\"\n",
    "    if btype != current_type:\n",
    "        if current_type is not None and current_bins:\n",
    "            phases.append({\n",
    "                \"type\": current_type,\n",
    "                \"start_min\": current_start_min,\n",
    "                \"end_min\": current_bins[-1][\"elapsed_min\"] + bin_s / 60.0,\n",
    "                \"bins\": current_bins,\n",
    "            })\n",
    "        current_type = btype\n",
    "        current_start_min = brow[\"elapsed_min\"]\n",
    "        current_bins = [brow.to_dict()]\n",
    "    else:\n",
    "        current_bins.append(brow.to_dict())\n",
    "\n",
    "if current_bins:\n",
    "    phases.append({\n",
    "        \"type\": current_type,\n",
    "        \"start_min\": current_start_min,\n",
    "        \"end_min\": current_bins[-1][\"elapsed_min\"] + bin_s / 60.0,\n",
    "        \"bins\": current_bins,\n",
    "    })\n",
    "\n",
    "# Merge short rest phases (< PHASE_MERGE_GAP_MIN) into adjacent active\n",
    "merged_phases = []\n",
    "for p in phases:\n",
    "    duration_min = p[\"end_min\"] - p[\"start_min\"]\n",
    "    if (p[\"type\"] == \"Rest\" and duration_min < PHASE_MERGE_GAP_MIN\n",
    "            and merged_phases and merged_phases[-1][\"type\"] == \"Active\"):\n",
    "        # Absorb into previous active phase\n",
    "        merged_phases[-1][\"end_min\"] = p[\"end_min\"]\n",
    "        merged_phases[-1][\"bins\"].extend(p[\"bins\"])\n",
    "    else:\n",
    "        merged_phases.append(p)\n",
    "\n",
    "# Second pass: merge adjacent Active phases that are now next to each other\n",
    "final_phases = []\n",
    "for p in merged_phases:\n",
    "    if final_phases and final_phases[-1][\"type\"] == p[\"type\"]:\n",
    "        final_phases[-1][\"end_min\"] = p[\"end_min\"]\n",
    "        final_phases[-1][\"bins\"].extend(p[\"bins\"])\n",
    "    else:\n",
    "        final_phases.append(p)\n",
    "merged_phases = final_phases\n",
    "\n",
    "# Build phase summary table\n",
    "phase_summary = []\n",
    "for i, p in enumerate(merged_phases):\n",
    "    phase_df = df[(df[\"elapsed_min\"] >= p[\"start_min\"]) & (df[\"elapsed_min\"] < p[\"end_min\"])]\n",
    "    if len(phase_df) == 0:\n",
    "        continue\n",
    "\n",
    "    dist = phase_df[\"step_dist_yd\"].sum()\n",
    "    dur_s = phase_df[\"dt\"].sum()\n",
    "    max_spd = phase_df[\"speed_mph\"].max()\n",
    "\n",
    "    # Intensity label\n",
    "    if p[\"type\"] == \"Rest\":\n",
    "        intensity = \"Rest\"\n",
    "    elif max_spd >= SPRINT_THRESHOLD_MPH:\n",
    "        intensity = \"High\"\n",
    "    elif max_spd >= HSR_THRESHOLD_MPH:\n",
    "        intensity = \"Moderate-High\"\n",
    "    elif max_spd >= 8.0:\n",
    "        intensity = \"Moderate\"\n",
    "    else:\n",
    "        intensity = \"Low\"\n",
    "\n",
    "    phase_summary.append({\n",
    "        \"phase\": i + 1,\n",
    "        \"type\": p[\"type\"],\n",
    "        \"intensity\": intensity,\n",
    "        \"start_min\": round(p[\"start_min\"], 1),\n",
    "        \"end_min\": round(p[\"end_min\"], 1),\n",
    "        \"duration_min\": round(dur_s / 60, 1),\n",
    "        \"distance_yd\": round(dist, 1),\n",
    "        \"distance_rate_yd_min\": round(dist / max(dur_s / 60, 0.01), 1),\n",
    "        \"max_speed_mph\": round(max_spd, 1),\n",
    "        \"hsr_distance_yd\": round(phase_df.loc[phase_df[\"is_hsr\"], \"step_dist_yd\"].sum(), 1),\n",
    "        \"sprint_distance_yd\": round(phase_df.loc[phase_df[\"is_sprint\"], \"step_dist_yd\"].sum(), 1),\n",
    "    })\n",
    "\n",
    "phase_df_summary = pd.DataFrame(phase_summary)\n",
    "\n",
    "print(f\"  Detected {len(phase_summary)} session phases:\")\n",
    "for _, p in phase_df_summary.iterrows():\n",
    "    print(f\"    Phase {int(p['phase']):2d} [{p['intensity']:13s}]: \"\n",
    "          f\"min {p['start_min']:5.1f}–{p['end_min']:5.1f} \"\n",
    "          f\"({p['duration_min']:4.1f} min, {p['distance_yd']:6.1f} yd, \"\n",
    "          f\"max {p['max_speed_mph']:.1f} mph)\")\n",
    "\n",
    "# Assign phase labels back to main df\n",
    "df[\"phase_id\"] = 0\n",
    "df[\"phase_intensity\"] = \"Unassigned\"\n",
    "for _, p in phase_df_summary.iterrows():\n",
    "    mask = (df[\"elapsed_min\"] >= p[\"start_min\"]) & (df[\"elapsed_min\"] < p[\"end_min\"])\n",
    "    df.loc[mask, \"phase_id\"] = int(p[\"phase\"])\n",
    "    df.loc[mask, \"phase_intensity\"] = p[\"intensity\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bc4654",
   "metadata": {},
   "source": [
    "## STEP 6: EARLY VS LATE COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb23fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 6: Early vs late half comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42106fb",
   "metadata": {},
   "source": [
    "## STEP 6: EARLY VS LATE COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c217de14",
   "metadata": {},
   "outputs": [],
   "source": [
    "midpoint_s = df[\"elapsed_s\"].iloc[-1] / 2\n",
    "early = df[df[\"elapsed_s\"] <= midpoint_s]\n",
    "late = df[df[\"elapsed_s\"] > midpoint_s]\n",
    "\n",
    "early_late = []\n",
    "for label, subset in [(\"Early Half\", early), (\"Late Half\", late)]:\n",
    "    d = {\n",
    "        \"period\": label,\n",
    "        \"duration_min\": round(subset[\"dt\"].sum() / 60, 1),\n",
    "        \"distance_yd\": round(subset[\"step_dist_yd\"].sum(), 1),\n",
    "        \"distance_rate_yd_min\": round(\n",
    "            subset[\"step_dist_yd\"].sum() / max(subset[\"dt\"].sum() / 60, 0.01), 1\n",
    "        ),\n",
    "        \"mean_speed_mph\": round(subset[\"speed_mph\"].mean(), 2),\n",
    "        \"max_speed_mph\": round(subset[\"speed_mph\"].max(), 2),\n",
    "        \"hsr_distance_yd\": round(subset.loc[subset[\"is_hsr\"], \"step_dist_yd\"].sum(), 1),\n",
    "        \"sprint_distance_yd\": round(subset.loc[subset[\"is_sprint\"], \"step_dist_yd\"].sum(), 1),\n",
    "        \"hsr_events\": len(count_events(subset[\"is_hsr\"].reset_index(drop=True), subset[\"dt\"].reset_index(drop=True))),\n",
    "        \"sprint_events\": len(count_events(subset[\"is_sprint\"].reset_index(drop=True), subset[\"dt\"].reset_index(drop=True))),\n",
    "        \"accel_events\": len(count_events(subset[\"is_accel\"].reset_index(drop=True), subset[\"dt\"].reset_index(drop=True))),\n",
    "        \"decel_events\": len(count_events(subset[\"is_decel\"].reset_index(drop=True), subset[\"dt\"].reset_index(drop=True))),\n",
    "    }\n",
    "    early_late.append(d)\n",
    "\n",
    "early_late_df = pd.DataFrame(early_late)\n",
    "\n",
    "# Add delta row\n",
    "early_d = early_late_df.iloc[0]\n",
    "late_d = early_late_df.iloc[1]\n",
    "if early_d[\"distance_yd\"] > 0:\n",
    "    dist_delta_pct = round((late_d[\"distance_yd\"] - early_d[\"distance_yd\"]) / early_d[\"distance_yd\"] * 100, 1)\n",
    "else:\n",
    "    dist_delta_pct = 0\n",
    "\n",
    "print(f\"  Early half: {early_d['distance_yd']:.1f} yd ({early_d['distance_rate_yd_min']:.1f} yd/min)\")\n",
    "print(f\"  Late half:  {late_d['distance_yd']:.1f} yd ({late_d['distance_rate_yd_min']:.1f} yd/min)\")\n",
    "print(f\"  Distance delta: {dist_delta_pct:+.1f}%\")\n",
    "print(f\"  HSR events: early={early_d['hsr_events']}, late={late_d['hsr_events']}\")\n",
    "print(f\"  Sprint events: early={early_d['sprint_events']}, late={late_d['sprint_events']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eb14ec",
   "metadata": {},
   "source": [
    "## STEP 7: POSITION / ROLE INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bac3940",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 7: Position / role inference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd41e854",
   "metadata": {},
   "source": [
    "## STEP 7: POSITION / ROLE INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cfb196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key indicators for position inference:\n",
    "# 1. Max speed (18.7 mph) — consistent with skill positions (WR, RB, DB, LB)\n",
    "# 2. Total distance for ~112 min session\n",
    "# 3. Movement pattern — do they move laterally or in straight lines?\n",
    "# 4. Field coverage area\n",
    "\n",
    "x_range = df[\"x\"].max() - df[\"x\"].min()\n",
    "y_range = df[\"y\"].max() - df[\"y\"].min()\n",
    "hsr_pct = metrics[\"hsr_distance_yd\"] / total_distance_yd * 100\n",
    "sprint_pct = metrics[\"sprint_distance_yd\"] / total_distance_yd * 100\n",
    "\n",
    "# Directional analysis — how often does player change direction?\n",
    "dir_changes = df[\"dir\"].diff().abs()\n",
    "# Normalize to [0, 180] (direction changes wrap around 360)\n",
    "dir_changes = dir_changes.where(dir_changes <= 180, 360 - dir_changes)\n",
    "mean_dir_change = dir_changes[normal].mean()\n",
    "\n",
    "print(f\"  Field coverage: X={x_range:.0f} yd, Y={y_range:.0f} yd\")\n",
    "print(f\"  HSR % of total distance: {hsr_pct:.1f}%\")\n",
    "print(f\"  Sprint % of total distance: {sprint_pct:.1f}%\")\n",
    "print(f\"  Mean direction change per sample: {mean_dir_change:.1f}°\")\n",
    "print(f\"  Max speed: {metrics['max_speed_mph']} mph\")\n",
    "print(f\"  Assessment: Skill position (likely WR/DB) — high max speed with\")\n",
    "print(f\"              frequent direction changes and broad field coverage.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810b2dfa",
   "metadata": {},
   "source": [
    "## STEP 8: FIGURE 1 — SPATIAL MOVEMENT MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4ba9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 8: Generating Figure 1 — Spatial Movement Map\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0accfeba",
   "metadata": {},
   "source": [
    "## STEP 8: FIGURE 1 — SPATIAL MOVEMENT MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5642db36",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, axes1 = plt.subplots(1, 2, figsize=(16, 8), gridspec_kw={\"width_ratios\": [1.2, 1]})\n",
    "\n",
    "# ── Left panel: Movement trace colored by speed band ─────────────────────\n",
    "ax = axes1[0]\n",
    "\n",
    "# Only plot continuous segments (skip gaps)\n",
    "band_colors = {\n",
    "    \"Standing\": \"#d4d4d4\",\n",
    "    \"Walking\": \"#93c5fd\",\n",
    "    \"Jogging\": \"#60a5fa\",\n",
    "    \"Running\": \"#f59e0b\",\n",
    "    \"High-Speed\": \"#ef4444\",\n",
    "    \"Sprint\": \"#dc2626\",\n",
    "}\n",
    "\n",
    "# Draw field outline (approximate)\n",
    "field_rect = plt.Rectangle(\n",
    "    (df[\"x\"].quantile(0.005), df[\"y\"].quantile(0.005)),\n",
    "    x_range * 0.99, y_range * 0.99,\n",
    "    linewidth=1.5, edgecolor=\"#9ca3af\", facecolor=\"#2d5016\", alpha=0.15, zorder=0\n",
    ")\n",
    "ax.add_patch(field_rect)\n",
    "\n",
    "# Plot movement by speed band (low speed first, high speed on top)\n",
    "for band_name in [\"Standing\", \"Walking\", \"Jogging\", \"Running\", \"High-Speed\", \"Sprint\"]:\n",
    "    band_mask = df[\"speed_band\"] == band_name\n",
    "    if band_mask.sum() > 0:\n",
    "        alpha = 0.15 if band_name in [\"Standing\", \"Walking\"] else 0.7\n",
    "        size = 0.3 if band_name in [\"Standing\", \"Walking\"] else 1.5\n",
    "        ax.scatter(\n",
    "            df.loc[band_mask, \"x\"], df.loc[band_mask, \"y\"],\n",
    "            c=band_colors[band_name], s=size, alpha=alpha,\n",
    "            label=band_name, zorder=1 if band_name in [\"Standing\", \"Walking\"] else 2,\n",
    "            rasterized=True,\n",
    "        )\n",
    "\n",
    "# Highlight peak windows on the map\n",
    "for pw in peak_windows:\n",
    "    if pw[\"window_s\"] <= 60:  # Only show shorter windows to avoid clutter\n",
    "        pw_slice = df.iloc[pw[\"start_idx\"]:pw[\"end_idx\"]+1]\n",
    "        ax.plot(pw_slice[\"x\"], pw_slice[\"y\"],\n",
    "                color=\"#facc15\", linewidth=2.5, alpha=0.9, zorder=5,\n",
    "                solid_capstyle=\"round\")\n",
    "\n",
    "ax.set_xlabel(\"X (yards)\", fontsize=11)\n",
    "ax.set_ylabel(\"Y (yards)\", fontsize=11)\n",
    "ax.set_title(\"Movement Trace — Colored by Speed Band\", fontsize=13, fontweight=\"bold\", pad=12)\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.grid(True, alpha=0.15)\n",
    "\n",
    "# Legend\n",
    "legend_patches = [mpatches.Patch(color=band_colors[b[\"name\"]], label=b[\"name\"]) for b in SPEED_BANDS]\n",
    "legend_patches.append(plt.Line2D([0], [0], color=\"#facc15\", linewidth=2.5, label=\"Peak Window\"))\n",
    "ax.legend(handles=legend_patches, loc=\"upper right\", fontsize=8, framealpha=0.9)\n",
    "\n",
    "# ── Right panel: Heatmap (density) ──────────────────────────────────────\n",
    "ax2 = axes1[1]\n",
    "\n",
    "# Create 2D histogram for position density\n",
    "x_bins = np.linspace(df[\"x\"].min() - 2, df[\"x\"].max() + 2, 80)\n",
    "y_bins = np.linspace(df[\"y\"].min() - 2, df[\"y\"].max() + 2, 80)\n",
    "heatmap, xedges, yedges = np.histogram2d(df[\"x\"], df[\"y\"], bins=[x_bins, y_bins])\n",
    "heatmap = gaussian_filter(heatmap.T, sigma=2)\n",
    "\n",
    "# Custom green-to-red colormap\n",
    "colors_heat = [\"#1a1a2e\", \"#16213e\", \"#0f3460\", \"#e94560\", \"#ffd700\"]\n",
    "cmap = LinearSegmentedColormap.from_list(\"field_heat\", colors_heat, N=256)\n",
    "\n",
    "im = ax2.imshow(\n",
    "    heatmap, origin=\"lower\", aspect=\"equal\",\n",
    "    extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]],\n",
    "    cmap=cmap, interpolation=\"gaussian\",\n",
    ")\n",
    "plt.colorbar(im, ax=ax2, label=\"Time Spent (relative)\", shrink=0.8)\n",
    "\n",
    "ax2.set_xlabel(\"X (yards)\", fontsize=11)\n",
    "ax2.set_ylabel(\"Y (yards)\", fontsize=11)\n",
    "ax2.set_title(\"Position Density Heatmap\", fontsize=13, fontweight=\"bold\", pad=12)\n",
    "ax2.grid(True, alpha=0.1, color=\"white\")\n",
    "\n",
    "fig1.suptitle(\n",
    "    \"WHERE: Spatial Usage and Role Signature\\n\"\n",
    "    f\"Assessment: Skill position (WR/DB) — {x_range:.0f}×{y_range:.0f} yd coverage, \"\n",
    "    f\"max {metrics['max_speed_mph']:.1f} mph\",\n",
    "    fontsize=14, fontweight=\"bold\", y=0.98\n",
    ")\n",
    "fig1.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "fig1.savefig(FIG_DIR / \"01_space.png\", dpi=180, bbox_inches=\"tight\", facecolor=\"white\")\n",
    "plt.close(fig1)\n",
    "print(\"  Saved: 01_space.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94a0a28",
   "metadata": {},
   "source": [
    "## STEP 9: FIGURE 2 — INTENSITY TIMELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb944d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 9: Generating Figure 2 — Intensity Timeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4105fd68",
   "metadata": {},
   "source": [
    "## STEP 9: FIGURE 2 — INTENSITY TIMELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4a5426",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure(figsize=(16, 9))\n",
    "gs = gridspec.GridSpec(3, 1, height_ratios=[3, 1, 0.4], hspace=0.08)\n",
    "\n",
    "# ── Top panel: Speed over time ───────────────────────────────────────────\n",
    "ax_speed = fig2.add_subplot(gs[0])\n",
    "\n",
    "# Resample to 1-second bins for cleaner plotting\n",
    "df[\"sec_bin\"] = (df[\"elapsed_s\"] // 1).astype(int)\n",
    "sec_agg = df.groupby(\"sec_bin\").agg(\n",
    "    speed_mph=(\"speed_mph\", \"mean\"),\n",
    "    elapsed_min=(\"elapsed_min\", \"mean\"),\n",
    "    step_dist_yd=(\"step_dist_yd\", \"sum\"),\n",
    "    max_speed_mph=(\"speed_mph\", \"max\"),\n",
    ").reset_index()\n",
    "\n",
    "ax_speed.fill_between(\n",
    "    sec_agg[\"elapsed_min\"], sec_agg[\"speed_mph\"],\n",
    "    color=\"#3b82f6\", alpha=0.4, linewidth=0\n",
    ")\n",
    "ax_speed.plot(sec_agg[\"elapsed_min\"], sec_agg[\"speed_mph\"],\n",
    "              color=\"#1d4ed8\", linewidth=0.5, alpha=0.7)\n",
    "\n",
    "# HSR threshold line\n",
    "ax_speed.axhline(HSR_THRESHOLD_MPH, color=\"#ef4444\", linestyle=\"--\", linewidth=1, alpha=0.7, label=f\"HSR ({HSR_THRESHOLD_MPH} mph)\")\n",
    "ax_speed.axhline(SPRINT_THRESHOLD_MPH, color=\"#dc2626\", linestyle=\":\", linewidth=1, alpha=0.5, label=f\"Sprint ({SPRINT_THRESHOLD_MPH} mph)\")\n",
    "\n",
    "# Highlight peak windows\n",
    "pw_colors = [\"#f59e0b\", \"#10b981\", \"#8b5cf6\", \"#ec4899\", \"#06b6d4\"]\n",
    "for i, pw in enumerate(peak_windows):\n",
    "    start_min = pw[\"start_elapsed_min\"]\n",
    "    end_min = pw[\"end_elapsed_min\"]\n",
    "    ax_speed.axvspan(start_min, end_min, alpha=0.15, color=pw_colors[i % len(pw_colors)], zorder=0)\n",
    "    ax_speed.text(\n",
    "        (start_min + end_min) / 2, ax_speed.get_ylim()[1] * 0.95 if i == 0 else ax_speed.get_ylim()[1] * (0.95 - 0.06 * i),\n",
    "        pw[\"window_label\"], ha=\"center\", fontsize=7, fontweight=\"bold\",\n",
    "        color=pw_colors[i % len(pw_colors)], alpha=0.9\n",
    "    )\n",
    "\n",
    "ax_speed.set_ylabel(\"Speed (mph)\", fontsize=11)\n",
    "ax_speed.set_xlim(0, df[\"elapsed_min\"].max())\n",
    "ax_speed.set_ylim(0, metrics[\"max_speed_mph\"] * 1.1)\n",
    "ax_speed.legend(loc=\"upper right\", fontsize=8)\n",
    "ax_speed.set_title(\n",
    "    \"WHEN: Intensity Over Time — Speed, Distance Rate, and Session Phases\",\n",
    "    fontsize=14, fontweight=\"bold\", pad=12\n",
    ")\n",
    "ax_speed.tick_params(labelbottom=False)\n",
    "ax_speed.grid(True, alpha=0.15)\n",
    "\n",
    "# ── Middle panel: Distance rate (rolling 60s yd/min) ─────────────────────\n",
    "ax_dist = fig2.add_subplot(gs[1], sharex=ax_speed)\n",
    "\n",
    "# 60-second rolling distance rate\n",
    "roll_60 = sec_agg[\"step_dist_yd\"].rolling(60, min_periods=30).sum()  # yd per 60s = yd/min\n",
    "ax_dist.fill_between(sec_agg[\"elapsed_min\"], roll_60.fillna(0),\n",
    "                      color=\"#10b981\", alpha=0.4, linewidth=0)\n",
    "ax_dist.plot(sec_agg[\"elapsed_min\"], roll_60, color=\"#059669\", linewidth=0.8)\n",
    "ax_dist.set_ylabel(\"Distance Rate\\n(yd/min, 60s window)\", fontsize=9)\n",
    "ax_dist.set_ylim(0, roll_60.max() * 1.2 if roll_60.max() > 0 else 10)\n",
    "ax_dist.tick_params(labelbottom=False)\n",
    "ax_dist.grid(True, alpha=0.15)\n",
    "\n",
    "# ── Bottom panel: Phase strip ────────────────────────────────────────────\n",
    "ax_phase = fig2.add_subplot(gs[2], sharex=ax_speed)\n",
    "\n",
    "intensity_colors = {\n",
    "    \"Rest\": \"#e5e7eb\",\n",
    "    \"Low\": \"#93c5fd\",\n",
    "    \"Moderate\": \"#60a5fa\",\n",
    "    \"Moderate-High\": \"#f59e0b\",\n",
    "    \"High\": \"#ef4444\",\n",
    "}\n",
    "\n",
    "for _, p in phase_df_summary.iterrows():\n",
    "    color = intensity_colors.get(p[\"intensity\"], \"#d1d5db\")\n",
    "    ax_phase.axvspan(p[\"start_min\"], p[\"end_min\"], color=color, alpha=0.8)\n",
    "\n",
    "ax_phase.set_xlabel(\"Elapsed Time (minutes)\", fontsize=11)\n",
    "ax_phase.set_yticks([])\n",
    "ax_phase.set_ylabel(\"Phase\", fontsize=9, rotation=0, labelpad=35)\n",
    "\n",
    "# Phase legend\n",
    "phase_patches = [mpatches.Patch(color=c, label=l) for l, c in intensity_colors.items()]\n",
    "ax_phase.legend(handles=phase_patches, loc=\"upper right\", fontsize=7, ncol=5, framealpha=0.9)\n",
    "\n",
    "fig2.tight_layout()\n",
    "fig2.savefig(FIG_DIR / \"02_time.png\", dpi=180, bbox_inches=\"tight\", facecolor=\"white\")\n",
    "plt.close(fig2)\n",
    "print(\"  Saved: 02_time.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc527a61",
   "metadata": {},
   "source": [
    "## STEP 10: FIGURE 3 — PEAK DEMAND PROFILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4c4473",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 10: Generating Figure 3 — Peak Demand Profile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aef0382",
   "metadata": {},
   "source": [
    "## STEP 10: FIGURE 3 — PEAK DEMAND PROFILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3188129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3 = plt.figure(figsize=(16, 8))\n",
    "gs3 = gridspec.GridSpec(1, 2, width_ratios=[1.3, 1], wspace=0.3)\n",
    "\n",
    "# ── Left panel: Peak intensity curve (yd/min vs duration) ────────────────\n",
    "ax_peak = fig3.add_subplot(gs3[0])\n",
    "\n",
    "if len(peak_windows_df) > 0:\n",
    "    ax_peak.plot(\n",
    "        peak_windows_df[\"window_s\"],\n",
    "        peak_windows_df[\"intensity_yd_min\"],\n",
    "        color=\"#1d4ed8\", linewidth=2.5, marker=\"o\", markersize=8,\n",
    "        markerfacecolor=\"#3b82f6\", markeredgecolor=\"white\", markeredgewidth=2,\n",
    "        zorder=3,\n",
    "    )\n",
    "    # Annotate each point\n",
    "    for _, pw in peak_windows_df.iterrows():\n",
    "        ax_peak.annotate(\n",
    "            f\"{pw['intensity_yd_min']:.0f}\\nyd/min\",\n",
    "            (pw[\"window_s\"], pw[\"intensity_yd_min\"]),\n",
    "            textcoords=\"offset points\", xytext=(0, 15),\n",
    "            ha=\"center\", fontsize=9, fontweight=\"bold\", color=\"#1e3a5f\",\n",
    "        )\n",
    "\n",
    "ax_peak.set_xlabel(\"Window Duration (seconds)\", fontsize=12)\n",
    "ax_peak.set_ylabel(\"Peak Intensity (yd/min)\", fontsize=12)\n",
    "ax_peak.set_title(\"Peak Demand Curve\", fontsize=13, fontweight=\"bold\")\n",
    "ax_peak.set_xticks([pw[\"window_s\"] for pw in peak_windows])\n",
    "ax_peak.set_xticklabels([pw[\"window_label\"] for pw in peak_windows])\n",
    "ax_peak.grid(True, alpha=0.2)\n",
    "ax_peak.set_ylim(0, peak_windows_df[\"intensity_yd_min\"].max() * 1.3 if len(peak_windows_df) > 0 else 100)\n",
    "\n",
    "# ── Right panel: Speed band distance breakdown ──────────────────────────\n",
    "ax_bands = fig3.add_subplot(gs3[1])\n",
    "\n",
    "band_names = [b[\"name\"] for b in SPEED_BANDS]\n",
    "band_dists = [speed_band_dist.loc[bn, \"distance_yd\"] if bn in speed_band_dist.index else 0 for bn in band_names]\n",
    "band_cols = [band_colors.get(bn, \"#999\") for bn in band_names]\n",
    "\n",
    "bars = ax_bands.barh(band_names, band_dists, color=band_cols, edgecolor=\"white\", linewidth=0.5)\n",
    "\n",
    "for bar, dist in zip(bars, band_dists):\n",
    "    if dist > 0:\n",
    "        pct = dist / total_distance_yd * 100\n",
    "        ax_bands.text(bar.get_width() + 5, bar.get_y() + bar.get_height() / 2,\n",
    "                      f\"{dist:.0f} yd ({pct:.1f}%)\",\n",
    "                      va=\"center\", fontsize=9, fontweight=\"bold\")\n",
    "\n",
    "ax_bands.set_xlabel(\"Distance (yards)\", fontsize=12)\n",
    "ax_bands.set_title(\"Distance by Speed Band\", fontsize=13, fontweight=\"bold\")\n",
    "ax_bands.grid(True, axis=\"x\", alpha=0.2)\n",
    "ax_bands.invert_yaxis()\n",
    "\n",
    "fig3.suptitle(\n",
    "    f\"WHAT: Peak Demands — Total Distance {total_distance_yd:.0f} yd | \"\n",
    "    f\"HSR {metrics['hsr_distance_yd']} yd | Sprint {metrics['sprint_distance_yd']} yd\",\n",
    "    fontsize=14, fontweight=\"bold\", y=0.98,\n",
    ")\n",
    "fig3.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "fig3.savefig(FIG_DIR / \"03_peaks.png\", dpi=180, bbox_inches=\"tight\", facecolor=\"white\")\n",
    "plt.close(fig3)\n",
    "print(\"  Saved: 03_peaks.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd65a58f",
   "metadata": {},
   "source": [
    "## STEP 11: EXPORT TABLES AND RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44735344",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 11: Exporting tables and results contract\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dadfa5",
   "metadata": {},
   "source": [
    "## STEP 11: EXPORT TABLES AND RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf2a432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed band table\n",
    "speed_band_export = speed_band_dist.reset_index()\n",
    "speed_band_export.columns = [\"Zone\", \"Distance (yd)\", \"Samples\", \"Time (s)\", \"Distance (%)\", \"Time (min)\", \"Time (%)\"]\n",
    "speed_band_export.to_csv(TABLE_DIR / \"speed_band_summary.csv\", index=False)\n",
    "print(\"  Saved: speed_band_summary.csv\")\n",
    "\n",
    "# Peak windows table\n",
    "peak_windows_df.to_csv(TABLE_DIR / \"peak_windows.csv\", index=False)\n",
    "print(\"  Saved: peak_windows.csv\")\n",
    "\n",
    "# Phase summary table\n",
    "phase_df_summary.to_csv(TABLE_DIR / \"phase_summary.csv\", index=False)\n",
    "print(\"  Saved: phase_summary.csv\")\n",
    "\n",
    "# Early vs late table\n",
    "early_late_df.to_csv(TABLE_DIR / \"early_vs_late.csv\", index=False)\n",
    "print(\"  Saved: early_vs_late.csv\")\n",
    "\n",
    "# Event counts table\n",
    "pd.DataFrame([event_counts]).to_csv(TABLE_DIR / \"event_counts.csv\", index=False)\n",
    "print(\"  Saved: event_counts.csv\")\n",
    "\n",
    "# Session metrics\n",
    "pd.DataFrame([metrics]).to_csv(TABLE_DIR / \"session_metrics.csv\", index=False)\n",
    "print(\"  Saved: session_metrics.csv\")\n",
    "\n",
    "# QC summary\n",
    "pd.DataFrame([qc_summary]).to_csv(TABLE_DIR / \"qc_summary.csv\", index=False)\n",
    "print(\"  Saved: qc_summary.csv\")\n",
    "\n",
    "# Results contract (JSON)\n",
    "contract = {\n",
    "    \"session_summary\": {**qc_summary, **metrics, **event_counts},\n",
    "    \"thresholds\": {\n",
    "        \"speed_bands_mph\": SPEED_BANDS,\n",
    "        \"hsr_threshold_mph\": HSR_THRESHOLD_MPH,\n",
    "        \"sprint_threshold_mph\": SPRINT_THRESHOLD_MPH,\n",
    "        \"accel_threshold_ms2\": ACCEL_THRESHOLD_MS2,\n",
    "        \"decel_threshold_ms2\": DECEL_THRESHOLD_MS2,\n",
    "    },\n",
    "    \"units\": {\n",
    "        \"distance\": \"yards\",\n",
    "        \"speed\": \"mph\",\n",
    "        \"acceleration\": \"m/s²\",\n",
    "        \"speed_conversion\": {\"from\": \"yd/s\", \"to\": \"mph\", \"factor\": YDS_TO_MPH},\n",
    "        \"accel_conversion\": {\"from\": \"yd/s²\", \"to\": \"m/s²\", \"factor\": YDS2_TO_MS2},\n",
    "    },\n",
    "    \"peak_windows\": peak_windows,\n",
    "    \"early_vs_late_delta_pct\": dist_delta_pct,\n",
    "    \"figures\": {\n",
    "        \"01_space\": str(FIG_DIR / \"01_space.png\"),\n",
    "        \"02_time\": str(FIG_DIR / \"02_time.png\"),\n",
    "        \"03_peaks\": str(FIG_DIR / \"03_peaks.png\"),\n",
    "    },\n",
    "}\n",
    "\n",
    "with open(OUT_DIR / \"results.json\", \"w\") as f:\n",
    "    json.dump(contract, f, indent=2, default=str)\n",
    "print(\"  Saved: results.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PIPELINE COMPLETE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eb05e6",
   "metadata": {},
   "source": [
    "## STEP 11: EXPORT TABLES AND RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670a7c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nAll outputs in: {OUT_DIR}\")\n",
    "print(f\"Figures: {list(FIG_DIR.glob('*.png'))}\")\n",
    "print(f\"Tables: {list(TABLE_DIR.glob('*.csv'))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
