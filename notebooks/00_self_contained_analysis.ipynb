{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Browns Tracking Analysis - Self-Contained Version\n",
    "\n",
    "**Purpose**: Complete player tracking analysis using only standard Python libraries.\n",
    "\n",
    "**No external package dependencies** - This notebook runs with just pandas, numpy, matplotlib, and scipy.\n",
    "\n",
    "## Analysis Overview\n",
    "\n",
    "This notebook answers three coaching questions:\n",
    "1. **Where** did the player spend time? (spatial usage)\n",
    "2. **When** did intensity happen? (session structure + peaks)\n",
    "3. **What** were peak demands? (workload metrics)\n",
    "\n",
    "## Data Source Decision\n",
    "\n",
    "**Primary distance metric**: Speed-integrated distance (`s * dt`)\n",
    "\n",
    "The vendor-provided `dis` column shows a **-74.66% systematic error** vs speed-integrated distance and is **rejected** from this analysis. XY-derived distance (r=0.998 with speed-integrated) validates the speed channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports only\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Constants (unit conversions and expected sample rate)\n",
    "YARDS_PER_SECOND_TO_MPH = 2.0454545454545454\n",
    "YARDS_PER_SECOND_SQ_TO_M_PER_SECOND_SQ = 0.9144\n",
    "EXPECTED_SAMPLE_HZ = 10.0\n",
    "EXPECTED_DT_SECONDS = 0.1\n",
    "\n",
    "# Speed bands (mph) - coach-readable zones\n",
    "SPEED_BANDS = [\n",
    "    (\"Walk\", 0.0, 3.0),\n",
    "    (\"Cruise\", 3.0, 9.0),\n",
    "    (\"Run\", 9.0, 13.0),\n",
    "    (\"HSR\", 13.0, 16.0),\n",
    "    (\"Sprint\", 16.0, float('inf'))\n",
    "]\n",
    "\n",
    "# Analysis thresholds\n",
    "HSR_THRESHOLD_MPH = 13.0\n",
    "SPRINT_THRESHOLD_MPH = 16.0\n",
    "ACCEL_THRESHOLD_MS2 = 3.0\n",
    "DECEL_THRESHOLD_MS2 = -3.0\n",
    "GAP_THRESHOLD_S = 0.15\n",
    "\n",
    "# Peak window durations to analyze (seconds)\n",
    "PEAK_WINDOWS_S = [30, 60, 180, 300]\n",
    "\n",
    "print(\"✓ Imports and constants loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Data Loading and Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tracking data\n",
    "DATA_PATH = Path(\"../data/tracking_data.csv\")\n",
    "OUTPUT_DIR = Path(\"../outputs\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Loading data from: {DATA_PATH}\")\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df[\"ts\"] = pd.to_datetime(df[\"ts\"], utc=True)\n",
    "df = df.sort_values(\"ts\").reset_index(drop=True)\n",
    "\n",
    "# Compute time deltas\n",
    "dt = df[\"ts\"].diff().dt.total_seconds()\n",
    "df[\"dt_s\"] = dt.fillna(EXPECTED_DT_SECONDS)\n",
    "\n",
    "# Unit conversions\n",
    "df[\"speed_mph\"] = df[\"s\"] * YARDS_PER_SECOND_TO_MPH\n",
    "df[\"accel_ms2\"] = df[\"a\"] * YARDS_PER_SECOND_SQ_TO_M_PER_SECOND_SQ\n",
    "df[\"signed_accel_ms2\"] = df[\"sa\"] * YARDS_PER_SECOND_SQ_TO_M_PER_SECOND_SQ\n",
    "\n",
    "# PRIMARY distance source: speed-integrated\n",
    "df[\"step_distance_yd\"] = df[\"s\"] * df[\"dt_s\"]\n",
    "\n",
    "# XY-derived distance for validation only\n",
    "xy_step = np.sqrt(df[\"x\"].diff()**2 + df[\"y\"].diff()**2)\n",
    "df[\"step_distance_xy_yd\"] = xy_step.fillna(0.0)\n",
    "\n",
    "# Continuity flags (gaps and jumps)\n",
    "df[\"gap_break\"] = df[\"dt_s\"] > GAP_THRESHOLD_S\n",
    "xy_speed = np.where(df[\"dt_s\"] > 0, df[\"step_distance_xy_yd\"] / df[\"dt_s\"], np.nan)\n",
    "df[\"jump_break\"] = np.isfinite(xy_speed) & (xy_speed > 14.0)  # Max plausible speed\n",
    "df[\"break_before\"] = df[\"gap_break\"] | df[\"jump_break\"]\n",
    "df[\"break_before\"].iloc[0] = False\n",
    "df[\"block_id\"] = df[\"break_before\"].cumsum()\n",
    "\n",
    "print(f\"\\n✓ Loaded {len(df):,} rows\")\n",
    "print(f\"  Time range: {df['ts'].iloc[0]} to {df['ts'].iloc[-1]}\")\n",
    "print(f\"  Duration: {(df['ts'].iloc[-1] - df['ts'].iloc[0]).total_seconds() / 60:.1f} minutes\")\n",
    "print(f\"  Gaps detected: {df['gap_break'].sum()}\")\n",
    "print(f\"  Continuity blocks: {df['block_id'].max() + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data quality checks\n",
    "print(\"Data Quality Summary:\\n\")\n",
    "\n",
    "# Cadence check\n",
    "on_cadence = ((df[\"dt_s\"] >= 0.08) & (df[\"dt_s\"] <= 0.12)).mean() * 100\n",
    "print(f\"  Samples on 10Hz cadence: {on_cadence:.1f}%\")\n",
    "\n",
    "# Gap analysis\n",
    "max_gap_s = df[\"dt_s\"].max()\n",
    "print(f\"  Max time gap: {max_gap_s:.2f}s\")\n",
    "\n",
    "# Speed validation (XY vs provided speed)\n",
    "xy_speed_calc = df[\"step_distance_xy_yd\"][1:] / df[\"dt_s\"][1:]\n",
    "speed_corr = np.corrcoef(df[\"s\"][1:], xy_speed_calc)[0, 1]\n",
    "print(f\"  Speed vs XY correlation: {speed_corr:.3f}\")\n",
    "\n",
    "# Distance validation\n",
    "speed_distance = df[\"step_distance_yd\"].sum()\n",
    "xy_distance = df[\"step_distance_xy_yd\"].sum()\n",
    "print(f\"\\n  Distance (speed-integrated): {speed_distance:.0f} yd\")\n",
    "print(f\"  Distance (XY-derived): {xy_distance:.0f} yd\")\n",
    "print(f\"  Agreement: {((xy_distance / speed_distance - 1) * 100):.1f}% difference\")\n",
    "\n",
    "# Inactive time\n",
    "inactive_pct = (df[\"speed_mph\"] <= 0.5).mean() * 100\n",
    "print(f\"\\n  Inactive time (<0.5 mph): {inactive_pct:.1f}%\")\n",
    "print(f\"  Peak speed: {df['speed_mph'].max():.1f} mph\")\n",
    "print(f\"  Peak accel: {df['signed_accel_ms2'].max():.2f} m/s²\")\n",
    "print(f\"  Peak decel: {df['signed_accel_ms2'].min():.2f} m/s²\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Analysis Functions\n",
    "\n",
    "These functions compute workload metrics, peak windows, and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_speed_band_summary(df, speed_bands):\n",
    "    \"\"\"Compute distance and time in each speed band.\"\"\"\n",
    "    rows = []\n",
    "    total_distance = df[\"step_distance_yd\"].sum()\n",
    "    total_time = df[\"dt_s\"].sum()\n",
    "    \n",
    "    for name, lower, upper in speed_bands:\n",
    "        mask = (df[\"speed_mph\"] >= lower) & (df[\"speed_mph\"] < upper)\n",
    "        distance_yd = df.loc[mask, \"step_distance_yd\"].sum()\n",
    "        time_s = df.loc[mask, \"dt_s\"].sum()\n",
    "        \n",
    "        rows.append({\n",
    "            \"speed_band\": name,\n",
    "            \"distance_yd\": distance_yd,\n",
    "            \"distance_pct\": (distance_yd / total_distance * 100) if total_distance > 0 else 0,\n",
    "            \"time_s\": time_s,\n",
    "            \"time_pct\": (time_s / total_time * 100) if total_time > 0 else 0,\n",
    "            \"mean_speed_mph\": df.loc[mask, \"speed_mph\"].mean() if mask.any() else 0\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def compute_rolling_peak_windows(df, windows_s):\n",
    "    \"\"\"Compute rolling distance for peak window detection.\"\"\"\n",
    "    # Set timestamp index\n",
    "    indexed = df.set_index(\"ts\").copy()\n",
    "    results = pd.DataFrame(index=indexed.index)\n",
    "    \n",
    "    for window_s in windows_s:\n",
    "        col_name = f\"distance_{window_s}s_yd\"\n",
    "        \n",
    "        # Rolling sum within blocks (respects continuity breaks)\n",
    "        rolling = indexed.groupby(\"block_id\")[\"step_distance_yd\"].rolling(\n",
    "            f\"{window_s}s\", closed=\"left\"\n",
    "        ).sum()\n",
    "        \n",
    "        results[col_name] = rolling.droplevel(0)\n",
    "    \n",
    "    return results.reset_index()\n",
    "\n",
    "\n",
    "def find_top_windows(rolling_df, metric_col, window_s, top_n=3):\n",
    "    \"\"\"Find top N non-overlapping windows.\"\"\"\n",
    "    ranked = rolling_df[[\"ts\", metric_col]].dropna().sort_values(\n",
    "        metric_col, ascending=False\n",
    "    )\n",
    "    \n",
    "    selected = []\n",
    "    for _, row in ranked.iterrows():\n",
    "        end_ts = row[\"ts\"]\n",
    "        start_ts = end_ts - pd.Timedelta(seconds=window_s)\n",
    "        \n",
    "        # Check for overlap with existing windows\n",
    "        overlaps = any(\n",
    "            (start_ts < w[\"end_ts\"]) and (end_ts > w[\"start_ts\"])\n",
    "            for w in selected\n",
    "        )\n",
    "        \n",
    "        if not overlaps:\n",
    "            selected.append({\n",
    "                \"window_s\": window_s,\n",
    "                \"start_ts\": start_ts,\n",
    "                \"end_ts\": end_ts,\n",
    "                \"distance_yd\": row[metric_col],\n",
    "                \"intensity_yd_per_min\": row[metric_col] * (60.0 / window_s)\n",
    "            })\n",
    "            \n",
    "            if len(selected) >= top_n:\n",
    "                break\n",
    "    \n",
    "    return pd.DataFrame(selected)\n",
    "\n",
    "\n",
    "def compute_event_counts(df, hsr_thresh, sprint_thresh, accel_thresh, decel_thresh):\n",
    "    \"\"\"Count HSR/sprint events and accel/decel events.\"\"\"\n",
    "    hsr_mask = df[\"speed_mph\"] >= hsr_thresh\n",
    "    sprint_mask = df[\"speed_mph\"] >= sprint_thresh\n",
    "    accel_mask = df[\"signed_accel_ms2\"] >= accel_thresh\n",
    "    decel_mask = df[\"signed_accel_ms2\"] <= decel_thresh\n",
    "    \n",
    "    # Count transitions (false-to-true events)\n",
    "    hsr_events = (hsr_mask & ~hsr_mask.shift(fill_value=False)).sum()\n",
    "    sprint_events = (sprint_mask & ~sprint_mask.shift(fill_value=False)).sum()\n",
    "    accel_events = (accel_mask & ~accel_mask.shift(fill_value=False)).sum()\n",
    "    decel_events = (decel_mask & ~decel_mask.shift(fill_value=False)).sum()\n",
    "    \n",
    "    return {\n",
    "        \"hsr_distance_yd\": df.loc[hsr_mask, \"step_distance_yd\"].sum(),\n",
    "        \"sprint_distance_yd\": df.loc[sprint_mask, \"step_distance_yd\"].sum(),\n",
    "        \"hsr_events\": hsr_events,\n",
    "        \"sprint_events\": sprint_events,\n",
    "        \"accel_events\": accel_events,\n",
    "        \"decel_events\": decel_events\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_early_late_comparison(df, hsr_thresh):\n",
    "    \"\"\"Compare first half vs second half workload.\"\"\"\n",
    "    midpoint = df[\"ts\"].iloc[0] + (df[\"ts\"].iloc[-1] - df[\"ts\"].iloc[0]) / 2\n",
    "    early = df[df[\"ts\"] <= midpoint]\n",
    "    late = df[df[\"ts\"] > midpoint]\n",
    "    \n",
    "    rows = []\n",
    "    for period, chunk in [(\"Early Half\", early), (\"Late Half\", late)]:\n",
    "        duration_min = (chunk[\"ts\"].iloc[-1] - chunk[\"ts\"].iloc[0]).total_seconds() / 60.0\n",
    "        hsr_dist = chunk.loc[chunk[\"speed_mph\"] >= hsr_thresh, \"step_distance_yd\"].sum()\n",
    "        \n",
    "        rows.append({\n",
    "            \"period\": period,\n",
    "            \"duration_min\": duration_min,\n",
    "            \"distance_yd\": chunk[\"step_distance_yd\"].sum(),\n",
    "            \"mean_speed_mph\": chunk[\"speed_mph\"].mean(),\n",
    "            \"peak_speed_mph\": chunk[\"speed_mph\"].max(),\n",
    "            \"hsr_distance_yd\": hsr_dist,\n",
    "        })\n",
    "    \n",
    "    result = pd.DataFrame(rows)\n",
    "    \n",
    "    # Add percentage change\n",
    "    early_dist = result.loc[0, \"distance_yd\"]\n",
    "    result[\"distance_vs_early_pct\"] = (result[\"distance_yd\"] / early_dist - 1) * 100\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"✓ Analysis functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Compute Workload Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute speed band summary\n",
    "speed_bands_df = compute_speed_band_summary(df, SPEED_BANDS)\n",
    "\n",
    "print(\"Speed Band Summary:\\n\")\n",
    "print(speed_bands_df.to_string(index=False))\n",
    "print(\"\\n✓ Speed bands computed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute rolling windows and find peak windows\n",
    "rolling_df = compute_rolling_peak_windows(df, PEAK_WINDOWS_S)\n",
    "\n",
    "# Find top 3 windows for each duration\n",
    "all_peak_windows = []\n",
    "peak_by_duration = []\n",
    "\n",
    "for window_s in PEAK_WINDOWS_S:\n",
    "    col_name = f\"distance_{window_s}s_yd\"\n",
    "    top_windows = find_top_windows(rolling_df, col_name, window_s, top_n=3)\n",
    "    all_peak_windows.append(top_windows)\n",
    "    \n",
    "    # Also get single best window for each duration\n",
    "    if not top_windows.empty:\n",
    "        best = top_windows.iloc[0]\n",
    "        peak_by_duration.append({\n",
    "            \"window_s\": window_s,\n",
    "            \"distance_yd\": best[\"distance_yd\"],\n",
    "            \"intensity_yd_per_min\": best[\"intensity_yd_per_min\"]\n",
    "        })\n",
    "\n",
    "peak_windows_df = pd.concat(all_peak_windows, ignore_index=True)\n",
    "peak_by_duration_df = pd.DataFrame(peak_by_duration)\n",
    "\n",
    "print(\"\\nPeak Windows by Duration (Best of Each):\\n\")\n",
    "print(peak_by_duration_df.to_string(index=False))\n",
    "print(\"\\n✓ Peak windows computed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute event counts\n",
    "events = compute_event_counts(\n",
    "    df, \n",
    "    HSR_THRESHOLD_MPH, \n",
    "    SPRINT_THRESHOLD_MPH, \n",
    "    ACCEL_THRESHOLD_MS2, \n",
    "    DECEL_THRESHOLD_MS2\n",
    ")\n",
    "\n",
    "print(\"\\nEvent Counts:\\n\")\n",
    "for key, value in events.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Early vs Late comparison\n",
    "early_late_df = compute_early_late_comparison(df, HSR_THRESHOLD_MPH)\n",
    "\n",
    "print(\"\\n\\nEarly vs Late Comparison:\\n\")\n",
    "print(early_late_df.to_string(index=False))\n",
    "print(\"\\n✓ Event counts and early/late computed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Generate Visualizations\n",
    "\n",
    "Create the three coach-ready figures: Movement Map, Intensity Timeline, and Peak Demand Summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1: Movement Map with Peak Windows\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Scatter plot colored by speed\n",
    "scatter = ax.scatter(\n",
    "    df[\"x\"], \n",
    "    df[\"y\"], \n",
    "    c=df[\"speed_mph\"], \n",
    "    cmap=\"YlOrRd\", \n",
    "    s=1, \n",
    "    alpha=0.6, \n",
    "    vmin=0, \n",
    "    vmax=20\n",
    ")\n",
    "\n",
    "# Overlay top 3 peak windows (best 60s windows)\n",
    "top_3_windows = peak_windows_df[peak_windows_df[\"window_s\"] == 60].head(3)\n",
    "for i, (_, window) in enumerate(top_3_windows.iterrows()):\n",
    "    window_df = df[(df[\"ts\"] >= window[\"start_ts\"]) & (df[\"ts\"] <= window[\"end_ts\"])]\n",
    "    ax.plot(\n",
    "        window_df[\"x\"], \n",
    "        window_df[\"y\"], \n",
    "        linewidth=3, \n",
    "        alpha=0.8, \n",
    "        label=f\"Peak {i+1} ({window['distance_yd']:.0f} yd)\"\n",
    "    )\n",
    "\n",
    "ax.set_xlabel(\"X Position (yards)\", fontsize=12)\n",
    "ax.set_ylabel(\"Y Position (yards)\", fontsize=12)\n",
    "ax.set_title(\"Movement Map: Spatial Coverage and Peak Windows\", fontsize=14, fontweight='bold')\n",
    "cbar = plt.colorbar(scatter, label=\"Speed (mph)\")\n",
    "ax.legend(loc='best')\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(OUTPUT_DIR / \"figures\" / \"01_space.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Figure 1 saved: 01_space.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: Intensity Timeline\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
    "\n",
    "# Top panel: Speed\n",
    "ax1.plot(df[\"ts\"], df[\"speed_mph\"], linewidth=0.5, alpha=0.7, color='steelblue')\n",
    "ax1.axhline(HSR_THRESHOLD_MPH, color='orange', linestyle='--', linewidth=2, label=f'HSR ({HSR_THRESHOLD_MPH} mph)')\n",
    "ax1.axhline(SPRINT_THRESHOLD_MPH, color='red', linestyle='--', linewidth=2, label=f'Sprint ({SPRINT_THRESHOLD_MPH} mph)')\n",
    "ax1.set_ylabel(\"Speed (mph)\", fontsize=12)\n",
    "ax1.set_title(\"Intensity Timeline: Speed and Distance Over Time\", fontsize=14, fontweight='bold')\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.grid(alpha=0.3)\n",
    "ax1.set_ylim(0, 20)\n",
    "\n",
    "# Bottom panel: Rolling 60s distance\n",
    "ax2.plot(\n",
    "    rolling_df[\"ts\"], \n",
    "    rolling_df[\"distance_60s_yd\"], \n",
    "    linewidth=1, \n",
    "    color='darkgreen',\n",
    "    label='60s Rolling Distance'\n",
    ")\n",
    "ax2.set_ylabel(\"60s Distance (yards)\", fontsize=12)\n",
    "ax2.set_xlabel(\"Time\", fontsize=12)\n",
    "ax2.legend(loc='upper right')\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "# Shade top 3 peak windows\n",
    "for _, window in top_3_windows.iterrows():\n",
    "    ax1.axvspan(window[\"start_ts\"], window[\"end_ts\"], alpha=0.2, color='red')\n",
    "    ax2.axvspan(window[\"start_ts\"], window[\"end_ts\"], alpha=0.2, color='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(OUTPUT_DIR / \"figures\" / \"02_time.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Figure 2 saved: 02_time.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3: Peak Demand Summary\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "bars = ax.bar(\n",
    "    peak_by_duration_df[\"window_s\"], \n",
    "    peak_by_duration_df[\"distance_yd\"], \n",
    "    color=colors[:len(peak_by_duration_df)], \n",
    "    alpha=0.7,\n",
    "    width=[20, 40, 100, 200]  # Variable widths for visual effect\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Window Duration (seconds)\", fontsize=12)\n",
    "ax.set_ylabel(\"Peak Distance (yards)\", fontsize=12)\n",
    "ax.set_title(\"Peak Demand: Maximum Distance by Window Duration\", fontsize=14, fontweight='bold')\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "# Add intensity values on bars\n",
    "for bar, (_, row) in zip(bars, peak_by_duration_df.iterrows()):\n",
    "    height = bar.get_height()\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width()/2., \n",
    "        height,\n",
    "        f\"{row['intensity_yd_per_min']:.0f} yd/min\",\n",
    "        ha='center', \n",
    "        va='bottom', \n",
    "        fontsize=10,\n",
    "        fontweight='bold'\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(OUTPUT_DIR / \"figures\" / \"03_peaks.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Figure 3 saved: 03_peaks.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build results dictionary\n",
    "results = {\n",
    "    \"metadata\": {\n",
    "        \"notebook_version\": \"1.0.0 - Self-Contained\",\n",
    "        \"analysis_date\": pd.Timestamp.now(tz='UTC').isoformat(),\n",
    "        \"data_source\": str(DATA_PATH)\n",
    "    },\n",
    "    \"assumptions\": {\n",
    "        \"distance_source\": \"speed_integrated\",\n",
    "        \"vendor_dis_status\": \"REJECTED (-74.66% systematic error vs speed-integrated)\",\n",
    "        \"distance_validation\": \"XY-derived distance (r=0.998) validates speed channel\",\n",
    "        \"speed_bands_mph\": {name: [low, high] for name, low, high in SPEED_BANDS},\n",
    "        \"hsr_threshold_mph\": HSR_THRESHOLD_MPH,\n",
    "        \"sprint_threshold_mph\": SPRINT_THRESHOLD_MPH,\n",
    "        \"accel_threshold_ms2\": ACCEL_THRESHOLD_MS2,\n",
    "        \"decel_threshold_ms2\": DECEL_THRESHOLD_MS2,\n",
    "        \"unit_conversions\": {\n",
    "            \"yd_s_to_mph\": YARDS_PER_SECOND_TO_MPH,\n",
    "            \"yd_s2_to_m_s2\": YARDS_PER_SECOND_SQ_TO_M_PER_SECOND_SQ\n",
    "        }\n",
    "    },\n",
    "    \"session_summary\": {\n",
    "        \"rows\": len(df),\n",
    "        \"start_ts_utc\": str(df[\"ts\"].iloc[0]),\n",
    "        \"end_ts_utc\": str(df[\"ts\"].iloc[-1]),\n",
    "        \"duration_s\": (df[\"ts\"].iloc[-1] - df[\"ts\"].iloc[0]).total_seconds(),\n",
    "        \"gap_count\": df[\"gap_break\"].sum(),\n",
    "        \"distance_yd_from_speed\": df[\"step_distance_yd\"].sum(),\n",
    "        \"distance_yd_from_xy\": df[\"step_distance_xy_yd\"].sum(),\n",
    "        \"mean_speed_mph\": df[\"speed_mph\"].mean(),\n",
    "        \"peak_speed_mph\": df[\"speed_mph\"].max(),\n",
    "        \"mean_accel_ms2\": df[\"signed_accel_ms2\"].mean(),\n",
    "        \"peak_accel_ms2\": df[\"signed_accel_ms2\"].max(),\n",
    "        \"peak_decel_ms2\": df[\"signed_accel_ms2\"].min()\n",
    "    },\n",
    "    \"qc_status\": \"QC PASS\" if on_cadence > 99.0 and max_gap_s < 1.0 else \"QC WARN\",\n",
    "    \"event_counts\": events,\n",
    "}\n",
    "\n",
    "# Save results.json\n",
    "results_path = OUTPUT_DIR / \"results.json\"\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"✓ Results saved: {results_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save CSV tables\n",
    "tables_dir = OUTPUT_DIR / \"tables\"\n",
    "tables_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "speed_bands_df.to_csv(tables_dir / \"speed_bands.csv\", index=False)\n",
    "peak_windows_df.to_csv(tables_dir / \"peak_windows.csv\", index=False)\n",
    "peak_by_duration_df.to_csv(tables_dir / \"peak_by_duration.csv\", index=False)\n",
    "early_late_df.to_csv(tables_dir / \"early_late_comparison.csv\", index=False)\n",
    "\n",
    "# Save events as CSV\n",
    "events_df = pd.DataFrame([events])\n",
    "events_df.to_csv(tables_dir / \"event_counts.csv\", index=False)\n",
    "\n",
    "print(\"✓ CSV tables saved:\")\n",
    "print(\"  - speed_bands.csv\")\n",
    "print(\"  - peak_windows.csv\")\n",
    "print(\"  - peak_by_duration.csv\")\n",
    "print(\"  - early_late_comparison.csv\")\n",
    "print(\"  - event_counts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary\n",
    "print(\"=\"*60)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nSession Summary:\")\n",
    "print(f\"  Duration: {results['session_summary']['duration_s']/60:.1f} minutes\")\n",
    "print(f\"  Total Distance: {results['session_summary']['distance_yd_from_speed']:.0f} yards\")\n",
    "print(f\"  Peak Speed: {results['session_summary']['peak_speed_mph']:.1f} mph\")\n",
    "print(f\"  HSR Distance: {events['hsr_distance_yd']:.0f} yards ({events['hsr_distance_yd']/results['session_summary']['distance_yd_from_speed']*100:.1f}%)\")\n",
    "print(f\"  Sprint Distance: {events['sprint_distance_yd']:.0f} yards\")\n",
    "\n",
    "print(\"\\nPeak Demands:\")\n",
    "for _, row in peak_by_duration_df.iterrows():\n",
    "    print(f\"  Best {row['window_s']}s window: {row['distance_yd']:.0f} yd ({row['intensity_yd_per_min']:.0f} yd/min)\")\n",
    "\n",
    "print(\"\\nEarly vs Late:\")\n",
    "late_change = early_late_df.loc[1, 'distance_vs_early_pct']\n",
    "if late_change > 0:\n",
    "    print(f\"  Late-session output +{late_change:.1f}% vs early half\")\n",
    "else:\n",
    "    print(f\"  Late-session output {late_change:.1f}% vs early half\")\n",
    "\n",
    "print(\"\\nOutputs:\")\n",
    "print(f\"  Figures: {OUTPUT_DIR / 'figures'}\")\n",
    "print(f\"  Tables: {OUTPUT_DIR / 'tables'}\")\n",
    "print(f\"  Results: {OUTPUT_DIR / 'results.json'}\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
